{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T01:38:08.170791Z",
     "iopub.status.busy": "2024-10-08T01:38:08.170192Z",
     "iopub.status.idle": "2024-10-08T01:38:11.084152Z",
     "shell.execute_reply": "2024-10-08T01:38:11.083554Z",
     "shell.execute_reply.started": "2024-10-08T01:38:08.170772Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import gc\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Input, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T01:38:11.085876Z",
     "iopub.status.busy": "2024-10-08T01:38:11.085250Z",
     "iopub.status.idle": "2024-10-08T01:38:11.091541Z",
     "shell.execute_reply": "2024-10-08T01:38:11.091016Z",
     "shell.execute_reply.started": "2024-10-08T01:38:11.085851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set global seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the list of IDs\n",
    "ids = [\"MMCS0002\", \"MMCS0003\", \"MMCS0005\", \"MMCS0007\", \"MMCS0008\", \"MMCS0009\", \"MMCS0010\", \"MMCS0011\", \"MMCS0016\"]\n",
    "\n",
    "# Define a dictionary to store results for each model and each ID\n",
    "results = {id_: {} for id_ in ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T01:38:11.092991Z",
     "iopub.status.busy": "2024-10-08T01:38:11.092398Z",
     "iopub.status.idle": "2024-10-08T01:38:11.100229Z",
     "shell.execute_reply": "2024-10-08T01:38:11.099761Z",
     "shell.execute_reply.started": "2024-10-08T01:38:11.092971Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [ 'HeartRate',\n",
    "     'HeartRate_15_Mean',\n",
    "     'HeartRate_15_Std',\n",
    "     'HeartRate_30_Mean',\n",
    "     'HeartRate_30_Std',\n",
    "     'HeartRate_60_Mean',\n",
    "     'HeartRate_60_Std',\n",
    "     'HeartRate_90_Mean',\n",
    "     'HeartRate_90_Std',\n",
    "     'HeartRate_180_Mean',\n",
    "     'HeartRate_180_Std',\n",
    "     'HeartRate_360_Mean',\n",
    "     'HeartRate_360_Std',\n",
    "     'HeartRate_720_Mean',\n",
    "     'HeartRate_720_Std',\n",
    "     'HeartRate_1440_Mean',\n",
    "     'HeartRate_1440_Std',\n",
    "     'HeartRate_Diff_Lag_15_Mean_15',\n",
    "     'HeartRate_Diff_Lag_15_Std_15',\n",
    "     'HeartRate_Diff_Lag_30_Mean_30',\n",
    "     'HeartRate_Diff_Lag_30_Std_30',\n",
    "     'HeartRate_Diff_Lag_60_Mean_60',\n",
    "     'HeartRate_Diff_Lag_60_Std_60',\n",
    "     'HeartRate_Diff_Lag_90_Mean_90',\n",
    "     'HeartRate_Diff_Lag_90_Std_90',\n",
    "     'HeartRate_EWMA_15_Mean',\n",
    "     'HeartRate_EWMA_15_Std',\n",
    "     'HeartRate_EWMA_30_Mean',\n",
    "     'HeartRate_EWMA_30_Std',\n",
    "     'HeartRate_EWMA_60_Mean',\n",
    "     'HeartRate_EWMA_60_Std',\n",
    "     'HeartRate_EWMA_90_Mean',\n",
    "     'HeartRate_EWMA_90_Std',\n",
    "     'HeartRate_EWMA_180_Mean',\n",
    "     'HeartRate_EWMA_180_Std',\n",
    "     'HeartRate_RoC_1',\n",
    "     'HeartRate_RoC_5',\n",
    "     'HeartRate_RoC_15',\n",
    "     'HeartRate_RoC_30',\n",
    "     'HeartRate_RoC_60',\n",
    "     'HeartRate_RoC_120',\n",
    "     'HeartRate_RoC_180',\n",
    "     'HeartRate_Autocorr_lag_5_15',\n",
    "     'HeartRate_Autocorr_lag_5_30',\n",
    "     'HeartRate_Autocorr_lag_5_60',\n",
    "     'HeartRate_Autocorr_lag_5_120',\n",
    "     'HeartRate_Autocorr_lag_30_180',\n",
    "     'HeartRate_Autocorr_lag_30_240',\n",
    "     'HeartRate_PSD_15',\n",
    "     'HeartRate_PSD_30',\n",
    "     'HeartRate_PSD_60',\n",
    "     'HeartRate_PSD_90',\n",
    "     'Sleep',\n",
    "     'Sleep_15min_Mean',\n",
    "     'Sleep_15min_Std',\n",
    "     'Sleep_30min_Mean',\n",
    "     'Sleep_30min_Std',\n",
    "     'Sleep_60min_Mean',\n",
    "     'Sleep_60min_Std',\n",
    "     'Sleep_90min_Mean',\n",
    "     'Sleep_90min_Std',\n",
    "     'Sleep_180min_Mean',\n",
    "     'Sleep_180min_Std',\n",
    "     'Sleep_240min_Mean',\n",
    "     'Sleep_240min_Std',\n",
    "     'Sleep_360min_Mean',\n",
    "     'Sleep_360min_Std',\n",
    "     'Sleep_720min_Mean',\n",
    "     'Sleep_720min_Std',\n",
    "     'Sleep_1440min_Mean',\n",
    "     'Sleep_1440min_Std',\n",
    "     'Sleep_15min_Skew',\n",
    "     'Sleep_15min_Kurt',\n",
    "     'Sleep_30min_Skew',\n",
    "     'Sleep_30min_Kurt',\n",
    "     'Sleep_60min_Skew',\n",
    "     'Sleep_60min_Kurt',\n",
    "     'Sleep_90min_Skew',\n",
    "     'Sleep_90min_Kurt',\n",
    "     'Sleep_15min_Sum',\n",
    "     'Sleep_30min_Sum',\n",
    "     'Sleep_60min_Sum',\n",
    "     'Sleep_90min_Sum',\n",
    "     'Sleep_180min_Sum',\n",
    "     'Sleep_240min_Sum',\n",
    "     'Sleep_RoC_1min',\n",
    "     'Sleep_RoC_5min',\n",
    "     'Sleep_RoC_15min',\n",
    "     'Sleep_RoC_30min',\n",
    "     'Sleep_RoC_60min',\n",
    "     'Sleep_RoC_120min',\n",
    "     'Sleep_RoC_180min',\n",
    "     'Sleep_PSD_15min',\n",
    "     'Sleep_PSD_30min',\n",
    "     'Sleep_PSD_60min',\n",
    "     'Sleep_PSD_90min',\n",
    "     'Intensity',\n",
    "     'Intensity_15min_Mean',\n",
    "     'Intensity_15min_Std',\n",
    "     'Intensity_30min_Mean',\n",
    "     'Intensity_30min_Std',\n",
    "     'Intensity_60min_Mean',\n",
    "     'Intensity_60min_Std',\n",
    "     'Intensity_90min_Mean',\n",
    "     'Intensity_90min_Std',\n",
    "     'Intensity_180min_Mean',\n",
    "     'Intensity_180min_Std',\n",
    "     'Intensity_240min_Mean',\n",
    "     'Intensity_240min_Std',\n",
    "     'Intensity_360min_Mean',\n",
    "     'Intensity_360min_Std',\n",
    "     'Intensity_720min_Mean',\n",
    "     'Intensity_720min_Std',\n",
    "     'Intensity_1440min_Mean',\n",
    "     'Intensity_1440min_Std',\n",
    "     'Intensity_15min_Sum',\n",
    "     'Intensity_30min_Sum',\n",
    "     'Intensity_60min_Sum',\n",
    "     'Intensity_90min_Sum',\n",
    "     'Intensity_180min_Sum',\n",
    "     'Intensity_240min_Sum',\n",
    "     'Intensity_RoC_1min',\n",
    "     'Intensity_RoC_5min',\n",
    "     'Intensity_RoC_15min',\n",
    "     'Intensity_RoC_30min',\n",
    "     'Intensity_RoC_60min',\n",
    "     'Intensity_RoC_120min',\n",
    "     'Intensity_RoC_180min',\n",
    "     'Intensity_Switch_Count_15min',\n",
    "     'Intensity_Switch_Count_30min',\n",
    "     'Intensity_Switch_Count_60min',\n",
    "     'Intensity_Switch_Count_90min',\n",
    "     'Intensity_Switch_Count_180min',\n",
    "     'Intensity_PSD_15min',\n",
    "     'Intensity_PSD_30min',\n",
    "     'Intensity_PSD_60min',\n",
    "     'Intensity_PSD_90min',\n",
    "     'Steps',\n",
    "     'Steps_Lag_1min',\n",
    "     'Steps_Lag_5min',\n",
    "     'Steps_Lag_15min',\n",
    "     'Steps_Lag_30min',\n",
    "     'Steps_Lag_60min',\n",
    "     'Steps_Lag_120min',\n",
    "     'Steps_Lag_180min',\n",
    "     'Steps_Lag_240min',\n",
    "     'Steps_Lag_360min',\n",
    "     'Steps_Lag_720min',\n",
    "     'Steps_Lag_1440min',\n",
    "     'Steps_Lag_Diff_5min',\n",
    "     'Steps_Lag_Diff_15min',\n",
    "     'Steps_Lag_Diff_30min',\n",
    "     'Steps_Lag_Diff_60min',\n",
    "     'Steps_Lag_Diff_120min',\n",
    "     'Steps_Lag_Diff_180min',\n",
    "     'Steps_Lag_Diff_240min',\n",
    "     'Steps_Lag_Diff_360min',\n",
    "     'Steps_15min_Mean',\n",
    "     'Steps_15min_Std',\n",
    "     'Steps_30min_Mean',\n",
    "     'Steps_30min_Std',\n",
    "     'Steps_60min_Mean',\n",
    "     'Steps_60min_Std',\n",
    "     'Steps_90min_Mean',\n",
    "     'Steps_90min_Std',\n",
    "     'Steps_180min_Mean',\n",
    "     'Steps_180min_Std',\n",
    "     'Steps_RoC_5min',\n",
    "     'Steps_RoC_15min',\n",
    "     'Steps_RoC_30min',\n",
    "     'Steps_RoC_60min',\n",
    "     'Steps_RoC_120min',\n",
    "     'Steps_RoC_180min',\n",
    "     'Steps_Lag_Diff_5min_15min_Mean',\n",
    "     'Steps_Lag_Diff_5min_15min_Std',\n",
    "     'Steps_Lag_Diff_5min_30min_Mean',\n",
    "     'Steps_Lag_Diff_5min_30min_Std',\n",
    "     'Steps_Lag_Diff_5min_60min_Mean',\n",
    "     'Steps_Lag_Diff_5min_60min_Std',\n",
    "     'minute',\n",
    "     'hour',\n",
    "     'day_of_week',\n",
    "     'day_of_month',\n",
    "     'SecondOfMinute_Sin',\n",
    "     'SecondOfMinute_Cos',\n",
    "     'MinuteOfHour_Sin',\n",
    "     'MinuteOfHour_Cos',\n",
    "     'HourOfDay_Sin',\n",
    "     'HourOfDay_Cos',\n",
    "     'DayOfWeek_Sin',\n",
    "     'DayOfWeek_Cos',\n",
    "     'Is_Weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T01:38:11.101365Z",
     "iopub.status.busy": "2024-10-08T01:38:11.100939Z",
     "iopub.status.idle": "2024-10-08T01:38:11.106061Z",
     "shell.execute_reply": "2024-10-08T01:38:11.105584Z",
     "shell.execute_reply.started": "2024-10-08T01:38:11.101347Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, head_size, num_heads, ff_dim, input_dim, dropout=0.0):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm(input_dim)\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=head_size, num_heads=num_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layer_norm2 = nn.LayerNorm(input_dim)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, input_dim)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Multi-head attention + residual connection\n",
    "        attn_output, _ = self.mha(x, x, x)\n",
    "        x = self.dropout1(attn_output) + x\n",
    "        x = self.layer_norm1(x)\n",
    "        \n",
    "        # Feed-forward network + residual connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.dropout2(ff_output) + x\n",
    "        x = self.layer_norm2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, num_classes, dropout=0.0, mlp_dropout=0.0):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Stacking transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(head_size, num_heads, ff_dim, input_dim, dropout)\n",
    "            for _ in range(num_transformer_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Global Average Pooling layer\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # MLP (Multi-layer Perceptron) layers\n",
    "        mlp_layers = []\n",
    "        prev_units = input_dim\n",
    "        for units in mlp_units:\n",
    "            mlp_layers.append(nn.Linear(prev_units, units))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(mlp_dropout))\n",
    "            prev_units = units\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "        # Output layer for classification\n",
    "        self.output_layer = nn.Linear(mlp_units[-1], num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        x = self.global_avg_pool(x.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T01:38:11.108010Z",
     "iopub.status.busy": "2024-10-08T01:38:11.107650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "------------------------------------------------------------------\n",
      "ID value MMCS0002\n",
      "{'LSTM (Validation)': {'Accuracy': [0.7719298245614035, 0.7719298245614035, 0.8270676691729323, 0.8115577889447236, 0.821608040201005], 'Precision': [0.768526200749219, 0.7523553700839021, 0.8141483740310528, 0.7780463086080125, 0.7965713838313381], 'Recall': [0.7719298245614035, 0.7719298245614035, 0.8270676691729323, 0.8115577889447236, 0.821608040201005], 'F1_Score': [0.7702181735264639, 0.7610470121492072, 0.8195741012415382, 0.7894588572848293, 0.8045364118876528], 'AUC_ROC': [0.7842620246398362, 0.7618908016152517, 0.8074631021999442, 0.7612695190590661, 0.7898891295278385], 'Confusion_Matrix': [array([[283,  44,   0],\n",
      "       [ 44,  25,   1],\n",
      "       [  2,   0,   0]]), array([[290,  36,   1],\n",
      "       [ 51,  18,   1],\n",
      "       [  1,   1,   0]]), array([[300,  25,   2],\n",
      "       [ 39,  30,   0],\n",
      "       [  1,   2,   0]]), array([[305,  22,   0],\n",
      "       [ 51,  18,   0],\n",
      "       [  1,   1,   0]]), array([[305,  22,   0],\n",
      "       [ 46,  22,   1],\n",
      "       [  2,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.87      0.86       327\\n         1.0       0.36      0.36      0.36        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.77       399\\n   macro avg       0.41      0.41      0.41       399\\nweighted avg       0.77      0.77      0.77       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.89      0.87       327\\n         1.0       0.33      0.26      0.29        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.77       399\\n   macro avg       0.39      0.38      0.38       399\\nweighted avg       0.75      0.77      0.76       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.92      0.90       327\\n         1.0       0.53      0.43      0.48        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.83       399\\n   macro avg       0.47      0.45      0.46       399\\nweighted avg       0.81      0.83      0.82       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.93      0.89       327\\n         1.0       0.44      0.26      0.33        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.81       398\\n   macro avg       0.43      0.40      0.41       398\\nweighted avg       0.78      0.81      0.79       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.93      0.90       327\\n         1.0       0.50      0.32      0.39        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.82       398\\n   macro avg       0.45      0.42      0.43       398\\nweighted avg       0.80      0.82      0.80       398\\n']}, 'Transformer (Validation)': {'Accuracy': [0.8370927318295739, 0.8245614035087719, 0.8370927318295739, 0.8793969849246231, 0.8417085427135679], 'Precision': [0.8184294032059098, 0.782482628866338, 0.8027863777089782, 0.8698866673794505, 0.8238761541698641], 'Recall': [0.8370927318295739, 0.8245614035087719, 0.8370927318295739, 0.8793969849246231, 0.8417085427135679], 'F1_Score': [0.825557472971863, 0.7843839857064769, 0.8010858633517352, 0.8695476994473376, 0.829634803016968], 'AUC_ROC': [0.8317567223442535, 0.8096169870773845, 0.7790695172274118, 0.8611281986799444, 0.8174829274084917], 'Confusion_Matrix': [array([[305,  22,   0],\n",
      "       [ 41,  29,   0],\n",
      "       [  0,   2,   0]]), array([[317,  10,   0],\n",
      "       [ 58,  12,   0],\n",
      "       [  1,   1,   0]]), array([[319,   8,   0],\n",
      "       [ 54,  15,   0],\n",
      "       [  1,   2,   0]]), array([[315,  12,   0],\n",
      "       [ 35,  34,   0],\n",
      "       [  0,   1,   1]]), array([[307,  20,   0],\n",
      "       [ 40,  28,   1],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.93      0.91       327\\n         1.0       0.55      0.41      0.47        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.84       399\\n   macro avg       0.48      0.45      0.46       399\\nweighted avg       0.82      0.84      0.83       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.97      0.90       327\\n         1.0       0.52      0.17      0.26        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.82       399\\n   macro avg       0.45      0.38      0.39       399\\nweighted avg       0.78      0.82      0.78       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.98      0.91       327\\n         1.0       0.60      0.22      0.32        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.84       399\\n   macro avg       0.48      0.40      0.41       399\\nweighted avg       0.80      0.84      0.80       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.96      0.93       327\\n         1.0       0.72      0.49      0.59        69\\n         2.0       1.00      0.50      0.67         2\\n\\n    accuracy                           0.88       398\\n   macro avg       0.87      0.65      0.73       398\\nweighted avg       0.87      0.88      0.87       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.94      0.91       327\\n         1.0       0.57      0.41      0.47        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.84       398\\n   macro avg       0.48      0.45      0.46       398\\nweighted avg       0.82      0.84      0.83       398\\n']}, 'XGBoost (Validation)': {'Accuracy': [0.8872180451127819, 0.9097744360902256, 0.9022556390977443, 0.907035175879397, 0.9221105527638191], 'Precision': [0.8763143280942882, 0.9056812002542212, 0.889913188769024, 0.8981209291895584, 0.9168784262220192], 'Recall': [0.8872180451127819, 0.9097744360902256, 0.9022556390977443, 0.907035175879397, 0.9221105527638191], 'F1_Score': [0.8799020769170022, 0.906357955700061, 0.893744596683346, 0.9013535609435817, 0.913150435535557], 'AUC_ROC': [0.9352809719730358, 0.9474686166615458, 0.9315422394369763, 0.9586353858348758, 0.943770076392659], 'Confusion_Matrix': [array([[313,  14,   0],\n",
      "       [ 29,  41,   0],\n",
      "       [  1,   1,   0]]), array([[315,  12,   0],\n",
      "       [ 24,  46,   0],\n",
      "       [  0,   0,   2]]), array([[318,   9,   0],\n",
      "       [ 27,  42,   0],\n",
      "       [  0,   3,   0]]), array([[316,  11,   0],\n",
      "       [ 24,  45,   0],\n",
      "       [  0,   2,   0]]), array([[325,   2,   0],\n",
      "       [ 27,  42,   0],\n",
      "       [  0,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.96      0.93       327\\n         1.0       0.73      0.59      0.65        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       399\\n   macro avg       0.55      0.51      0.53       399\\nweighted avg       0.88      0.89      0.88       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.96      0.95       327\\n         1.0       0.79      0.66      0.72        70\\n         2.0       1.00      1.00      1.00         2\\n\\n    accuracy                           0.91       399\\n   macro avg       0.91      0.87      0.89       399\\nweighted avg       0.91      0.91      0.91       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.97      0.95       327\\n         1.0       0.78      0.61      0.68        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       399\\n   macro avg       0.57      0.53      0.54       399\\nweighted avg       0.89      0.90      0.89       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.97      0.95       327\\n         1.0       0.78      0.65      0.71        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       398\\n   macro avg       0.57      0.54      0.55       398\\nweighted avg       0.90      0.91      0.90       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.99      0.96       327\\n         1.0       0.91      0.61      0.73        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       398\\n   macro avg       0.61      0.53      0.56       398\\nweighted avg       0.92      0.92      0.91       398\\n']}, 'DecisionTree (Validation)': {'Accuracy': [0.8446115288220551, 0.8370927318295739, 0.8295739348370927, 0.8065326633165829, 0.864321608040201], 'Precision': [0.8417710944026734, 0.8562430437115153, 0.8377089162673814, 0.8043532775249472, 0.8580491744436468], 'Recall': [0.8446115288220551, 0.8370927318295739, 0.8295739348370927, 0.8065326633165829, 0.864321608040201], 'F1_Score': [0.8429260769436351, 0.8458620509607352, 0.8332499470398718, 0.8054196736912684, 0.8605460217006321], 'AUC_ROC': [0.7324453836056816, 0.7834345441197363, 0.7454545454545456, 0.6678584833739164, 0.7527724913850177], 'Confusion_Matrix': [array([[298,  29,   0],\n",
      "       [ 32,  37,   1],\n",
      "       [  0,   0,   2]]), array([[291,  35,   1],\n",
      "       [ 22,  43,   5],\n",
      "       [  0,   2,   0]]), array([[291,  36,   0],\n",
      "       [ 28,  39,   2],\n",
      "       [  0,   2,   1]]), array([[290,  36,   1],\n",
      "       [ 39,  30,   0],\n",
      "       [  0,   1,   1]]), array([[306,  21,   0],\n",
      "       [ 29,  38,   2],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.91      0.91       327\\n         1.0       0.56      0.53      0.54        70\\n         2.0       0.67      1.00      0.80         2\\n\\n    accuracy                           0.84       399\\n   macro avg       0.71      0.81      0.75       399\\nweighted avg       0.84      0.84      0.84       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.89      0.91       327\\n         1.0       0.54      0.61      0.57        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.84       399\\n   macro avg       0.49      0.50      0.49       399\\nweighted avg       0.86      0.84      0.85       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.89      0.90       327\\n         1.0       0.51      0.57      0.53        69\\n         2.0       0.33      0.33      0.33         3\\n\\n    accuracy                           0.83       399\\n   macro avg       0.58      0.60      0.59       399\\nweighted avg       0.84      0.83      0.83       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.89      0.88       327\\n         1.0       0.45      0.43      0.44        69\\n         2.0       0.50      0.50      0.50         2\\n\\n    accuracy                           0.81       398\\n   macro avg       0.61      0.61      0.61       398\\nweighted avg       0.80      0.81      0.81       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.94      0.92       327\\n         1.0       0.63      0.55      0.59        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.86       398\\n   macro avg       0.51      0.50      0.50       398\\nweighted avg       0.86      0.86      0.86       398\\n']}, 'RandomForest (Validation)': {'Accuracy': [0.8771929824561403, 0.8947368421052632, 0.8796992481203008, 0.9045226130653267, 0.9020100502512562], 'Precision': [0.8634014613999789, 0.8838626356551605, 0.8630219616838706, 0.8948608312599781, 0.8989848922684847], 'Recall': [0.8771929824561403, 0.8947368421052632, 0.8796992481203008, 0.9045226130653267, 0.9020100502512562], 'F1_Score': [0.8634377268994371, 0.8867820472841089, 0.8655123782096092, 0.8953906025967769, 0.8874449860094681], 'AUC_ROC': [0.9243570057884604, 0.944144598239943, 0.9368702691071114, 0.959074402633598, 0.9455503222978033], 'Confusion_Matrix': [array([[317,  10,   0],\n",
      "       [ 37,  33,   0],\n",
      "       [  1,   1,   0]]), array([[316,  11,   0],\n",
      "       [ 29,  41,   0],\n",
      "       [  0,   2,   0]]), array([[318,   9,   0],\n",
      "       [ 36,  33,   0],\n",
      "       [  0,   3,   0]]), array([[320,   7,   0],\n",
      "       [ 29,  40,   0],\n",
      "       [  0,   2,   0]]), array([[325,   2,   0],\n",
      "       [ 35,  34,   0],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.97      0.93       327\\n         1.0       0.75      0.47      0.58        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.88       399\\n   macro avg       0.55      0.48      0.50       399\\nweighted avg       0.86      0.88      0.86       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.97      0.94       327\\n         1.0       0.76      0.59      0.66        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       399\\n   macro avg       0.56      0.52      0.53       399\\nweighted avg       0.88      0.89      0.89       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.97      0.93       327\\n         1.0       0.73      0.48      0.58        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.88       399\\n   macro avg       0.54      0.48      0.50       399\\nweighted avg       0.86      0.88      0.87       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.98      0.95       327\\n         1.0       0.82      0.58      0.68        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       398\\n   macro avg       0.58      0.52      0.54       398\\nweighted avg       0.89      0.90      0.90       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.99      0.94       327\\n         1.0       0.92      0.49      0.64        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       398\\n   macro avg       0.61      0.50      0.53       398\\nweighted avg       0.90      0.90      0.89       398\\n']}, 'CNN_LSTM (Validation)': {'Accuracy': [0.8245614035087719, 0.8320802005012531, 0.8421052631578947, 0.8241206030150754, 0.8266331658291457], 'Precision': [0.784133817393087, 0.8001395364157108, 0.8252117049630544, 0.7936645251574327, 0.7865458243598946], 'Recall': [0.8245614035087719, 0.8320802005012531, 0.8421052631578947, 0.8241206030150754, 0.8266331658291457], 'F1_Score': [0.7811754756737611, 0.7988707665806256, 0.7990076381625498, 0.7515822417721107, 0.7840500614475678], 'AUC_ROC': [0.7714453258280857, 0.7606313944149009, 0.7829716336295283, 0.80838062729314, 0.7826300894115996], 'Confusion_Matrix': [array([[318,   9,   0],\n",
      "       [ 59,  11,   0],\n",
      "       [  2,   0,   0]]), array([[316,  11,   0],\n",
      "       [ 54,  16,   0],\n",
      "       [  2,   0,   0]]), array([[323,   4,   0],\n",
      "       [ 56,  13,   0],\n",
      "       [  3,   0,   0]]), array([[326,   1,   0],\n",
      "       [ 67,   2,   0],\n",
      "       [  2,   0,   0]]), array([[318,   9,   0],\n",
      "       [ 58,  11,   0],\n",
      "       [  2,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.97      0.90       327\\n         1.0       0.55      0.16      0.24        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.82       399\\n   macro avg       0.46      0.38      0.38       399\\nweighted avg       0.78      0.82      0.78       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.97      0.90       327\\n         1.0       0.59      0.23      0.33        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.83       399\\n   macro avg       0.48      0.40      0.41       399\\nweighted avg       0.80      0.83      0.80       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.99      0.91       327\\n         1.0       0.76      0.19      0.30        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.84       399\\n   macro avg       0.54      0.39      0.40       399\\nweighted avg       0.83      0.84      0.80       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      1.00      0.90       327\\n         1.0       0.67      0.03      0.06        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.82       398\\n   macro avg       0.50      0.34      0.32       398\\nweighted avg       0.79      0.82      0.75       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.97      0.90       327\\n         1.0       0.55      0.16      0.25        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.83       398\\n   macro avg       0.46      0.38      0.38       398\\nweighted avg       0.79      0.83      0.78       398\\n']}, 'SVM (Validation)': {'Accuracy': [0.8270676691729323, 0.8295739348370927, 0.7744360902255639, 0.8341708542713567, 0.8190954773869347], 'Precision': [0.8238444443782026, 0.8401845859374174, 0.7936744388451875, 0.8400450852392805, 0.8046529085053752], 'Recall': [0.8270676691729323, 0.8295739348370927, 0.7744360902255639, 0.8341708542713567, 0.8190954773869347], 'F1_Score': [0.8254446323740567, 0.8340691022527806, 0.7827124693116146, 0.8368811650846827, 0.8109141767953065], 'AUC_ROC': [0.8319510846465226, 0.8669322254993385, 0.7994816586921849, 0.8437337419017243, 0.8195372737099199], 'Confusion_Matrix': [array([[295,  32,   0],\n",
      "       [ 34,  35,   1],\n",
      "       [  0,   2,   0]]), array([[288,  39,   0],\n",
      "       [ 28,  41,   1],\n",
      "       [  0,   0,   2]]), array([[276,  50,   1],\n",
      "       [ 35,  33,   1],\n",
      "       [  0,   3,   0]]), array([[292,  35,   0],\n",
      "       [ 29,  39,   1],\n",
      "       [  0,   1,   1]]), array([[299,  28,   0],\n",
      "       [ 41,  27,   1],\n",
      "       [  0,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.90      0.90       327\\n         1.0       0.51      0.50      0.50        70\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.83       399\\n   macro avg       0.47      0.47      0.47       399\\nweighted avg       0.82      0.83      0.83       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.88      0.90       327\\n         1.0       0.51      0.59      0.55        70\\n         2.0       0.67      1.00      0.80         2\\n\\n    accuracy                           0.83       399\\n   macro avg       0.70      0.82      0.75       399\\nweighted avg       0.84      0.83      0.83       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.84      0.87       327\\n         1.0       0.38      0.48      0.43        69\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.77       399\\n   macro avg       0.42      0.44      0.43       399\\nweighted avg       0.79      0.77      0.78       399\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.89      0.90       327\\n         1.0       0.52      0.57      0.54        69\\n         2.0       0.50      0.50      0.50         2\\n\\n    accuracy                           0.83       398\\n   macro avg       0.64      0.65      0.65       398\\nweighted avg       0.84      0.83      0.84       398\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.91      0.90       327\\n         1.0       0.47      0.39      0.43        69\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.82       398\\n   macro avg       0.45      0.44      0.44       398\\nweighted avg       0.80      0.82      0.81       398\\n']}, 'LSTM (Test)': {'Accuracy': [0.7955911823647295, 0.7975951903807615, 0.8276553106212425, 0.7975951903807615, 0.8016032064128257], 'Precision': [0.7795829394638333, 0.7717288699003391, 0.816128897754154, 0.7827660686900293, 0.7725633084350519], 'Recall': [0.7955911823647295, 0.7975951903807615, 0.8276553106212425, 0.7975951903807615, 0.8016032064128257], 'F1_Score': [0.7869852906649188, 0.7812497288950194, 0.8209976074598176, 0.7890905652794585, 0.7837092323634312], 'AUC_ROC': [0.8115440889783185, 0.7652159680044921, 0.8233679454813864, 0.7843833811967464, 0.777961598807456], 'Confusion_Matrix': [array([[366,  43,   0],\n",
      "       [ 56,  31,   0],\n",
      "       [  2,   1,   0]]), array([[374,  34,   1],\n",
      "       [ 62,  23,   2],\n",
      "       [  2,   0,   1]]), array([[374,  34,   1],\n",
      "       [ 47,  39,   1],\n",
      "       [  3,   0,   0]]), array([[368,  40,   1],\n",
      "       [ 55,  30,   2],\n",
      "       [  3,   0,   0]]), array([[376,  32,   1],\n",
      "       [ 63,  24,   0],\n",
      "       [  1,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.89      0.88       409\\n         1.0       0.41      0.36      0.38        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.80       499\\n   macro avg       0.43      0.42      0.42       499\\nweighted avg       0.78      0.80      0.79       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.91      0.88       409\\n         1.0       0.40      0.26      0.32        87\\n         2.0       0.25      0.33      0.29         3\\n\\n    accuracy                           0.80       499\\n   macro avg       0.50      0.50      0.50       499\\nweighted avg       0.77      0.80      0.78       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.91      0.90       409\\n         1.0       0.53      0.45      0.49        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.83       499\\n   macro avg       0.47      0.45      0.46       499\\nweighted avg       0.82      0.83      0.82       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.90      0.88       409\\n         1.0       0.43      0.34      0.38        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.80       499\\n   macro avg       0.43      0.41      0.42       499\\nweighted avg       0.78      0.80      0.79       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.92      0.89       409\\n         1.0       0.41      0.28      0.33        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.80       499\\n   macro avg       0.42      0.40      0.41       499\\nweighted avg       0.77      0.80      0.78       499\\n']}, 'Transformer (Test)': {'Accuracy': [0.8416833667334669, 0.8236472945891784, 0.8196392785571143, 0.843687374749499, 0.8476953907815631], 'Precision': [0.8185866851588387, 0.7825245577597414, 0.7710662414976704, 0.8190601647280104, 0.828030239263498], 'Recall': [0.8416833667334669, 0.8236472945891784, 0.8196392785571143, 0.843687374749499, 0.8476953907815631], 'F1_Score': [0.8253866722869947, 0.7831576195870001, 0.771569854974928, 0.8246346117906491, 0.834534348656696], 'AUC_ROC': [0.8568451741496703, 0.7743242818936409, 0.7486903932791635, 0.8056661013156214, 0.8387246122896174], 'Confusion_Matrix': [array([[387,  22,   0],\n",
      "       [ 54,  33,   0],\n",
      "       [  1,   2,   0]]), array([[396,  13,   0],\n",
      "       [ 72,  15,   0],\n",
      "       [  3,   0,   0]]), array([[398,  11,   0],\n",
      "       [ 76,  11,   0],\n",
      "       [  3,   0,   0]]), array([[390,  19,   0],\n",
      "       [ 56,  31,   0],\n",
      "       [  1,   2,   0]]), array([[386,  23,   0],\n",
      "       [ 50,  37,   0],\n",
      "       [  1,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.95      0.91       409\\n         1.0       0.58      0.38      0.46        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.84       499\\n   macro avg       0.48      0.44      0.46       499\\nweighted avg       0.82      0.84      0.83       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.97      0.90       409\\n         1.0       0.54      0.17      0.26        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.82       499\\n   macro avg       0.46      0.38      0.39       499\\nweighted avg       0.78      0.82      0.78       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.97      0.90       409\\n         1.0       0.50      0.13      0.20        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.82       499\\n   macro avg       0.44      0.37      0.37       499\\nweighted avg       0.77      0.82      0.77       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.87      0.95      0.91       409\\n         1.0       0.60      0.36      0.45        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.84       499\\n   macro avg       0.49      0.44      0.45       499\\nweighted avg       0.82      0.84      0.82       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.94      0.91       409\\n         1.0       0.60      0.43      0.50        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.85       499\\n   macro avg       0.49      0.46      0.47       499\\nweighted avg       0.83      0.85      0.83       499\\n']}, 'XGBoost (Test)': {'Accuracy': [0.9118236472945892, 0.8957915831663327, 0.9138276553106213, 0.9018036072144289, 0.9098196392785571], 'Precision': [0.9021580082634666, 0.8856354217869702, 0.9044204724828268, 0.8910876698451848, 0.899801718901157], 'Recall': [0.9118236472945892, 0.8957915831663327, 0.9138276553106213, 0.9018036072144289, 0.9098196392785571], 'F1_Score': [0.9052855798556265, 0.8898101213319887, 0.907619880005565, 0.8945812821087807, 0.9023886482642705], 'AUC_ROC': [0.9315459232136541, 0.9341546448501276, 0.939938342251542, 0.9423441194599939, 0.9357698336785621], 'Confusion_Matrix': [array([[398,  11,   0],\n",
      "       [ 30,  57,   0],\n",
      "       [  0,   3,   0]]), array([[392,  17,   0],\n",
      "       [ 32,  55,   0],\n",
      "       [  0,   3,   0]]), array([[398,  11,   0],\n",
      "       [ 29,  58,   0],\n",
      "       [  0,   3,   0]]), array([[396,  13,   0],\n",
      "       [ 33,  54,   0],\n",
      "       [  0,   3,   0]]), array([[399,  10,   0],\n",
      "       [ 32,  55,   0],\n",
      "       [  0,   3,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.97      0.95       409\\n         1.0       0.80      0.66      0.72        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.91       499\\n   macro avg       0.58      0.54      0.56       499\\nweighted avg       0.90      0.91      0.91       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.96      0.94       409\\n         1.0       0.73      0.63      0.68        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       499\\n   macro avg       0.55      0.53      0.54       499\\nweighted avg       0.89      0.90      0.89       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.97      0.95       409\\n         1.0       0.81      0.67      0.73        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.91       499\\n   macro avg       0.58      0.55      0.56       499\\nweighted avg       0.90      0.91      0.91       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.97      0.95       409\\n         1.0       0.77      0.62      0.69        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       499\\n   macro avg       0.56      0.53      0.54       499\\nweighted avg       0.89      0.90      0.89       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.98      0.95       409\\n         1.0       0.81      0.63      0.71        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.91       499\\n   macro avg       0.58      0.54      0.55       499\\nweighted avg       0.90      0.91      0.90       499\\n']}, 'DecisionTree (Test)': {'Accuracy': [0.8537074148296593, 0.779559118236473, 0.8296593186372746, 0.8236472945891784, 0.8336673346693386], 'Precision': [0.8555444221776887, 0.8061767423668796, 0.8340500671199523, 0.8208514590155922, 0.8337650885407568], 'Recall': [0.8537074148296593, 0.779559118236473, 0.8296593186372746, 0.8236472945891784, 0.8336673346693386], 'F1_Score': [0.8546247942641709, 0.7913669922097694, 0.8317248748110472, 0.8222454187985251, 0.8336316736705409], 'AUC_ROC': [0.7646031248912553, 0.6942650154852628, 0.7326721648049552, 0.7067049883425548, 0.7301408027977868], 'Confusion_Matrix': [array([[374,  32,   3],\n",
      "       [ 34,  52,   1],\n",
      "       [  0,   3,   0]]), array([[345,  60,   4],\n",
      "       [ 40,  44,   3],\n",
      "       [  0,   3,   0]]), array([[367,  41,   1],\n",
      "       [ 38,  46,   3],\n",
      "       [  0,   2,   1]]), array([[367,  41,   1],\n",
      "       [ 43,  44,   0],\n",
      "       [  0,   3,   0]]), array([[367,  41,   1],\n",
      "       [ 38,  49,   0],\n",
      "       [  1,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.91      0.92       409\\n         1.0       0.60      0.60      0.60        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.85       499\\n   macro avg       0.50      0.50      0.50       499\\nweighted avg       0.86      0.85      0.85       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.84      0.87       409\\n         1.0       0.41      0.51      0.45        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.78       499\\n   macro avg       0.44      0.45      0.44       499\\nweighted avg       0.81      0.78      0.79       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.90      0.90       409\\n         1.0       0.52      0.53      0.52        87\\n         2.0       0.20      0.33      0.25         3\\n\\n    accuracy                           0.83       499\\n   macro avg       0.54      0.59      0.56       499\\nweighted avg       0.83      0.83      0.83       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.90      0.90       409\\n         1.0       0.50      0.51      0.50        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.82       499\\n   macro avg       0.47      0.47      0.47       499\\nweighted avg       0.82      0.82      0.82       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.90      0.90       409\\n         1.0       0.53      0.56      0.55        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.83       499\\n   macro avg       0.48      0.49      0.48       499\\nweighted avg       0.83      0.83      0.83       499\\n']}, 'RandomForest (Test)': {'Accuracy': [0.9018036072144289, 0.8937875751503006, 0.9038076152304609, 0.9038076152304609, 0.8897795591182365], 'Precision': [0.890752321354866, 0.881524327390413, 0.8933091124235146, 0.8933091124235146, 0.8767571589648545], 'Recall': [0.9018036072144289, 0.8937875751503006, 0.9038076152304609, 0.9038076152304609, 0.8897795591182365], 'F1_Score': [0.8933724185364815, 0.8842359084950605, 0.8938960917463378, 0.8938960917463378, 0.8784945709671171], 'AUC_ROC': [0.9249107747631532, 0.9150602009600857, 0.9301551178879318, 0.9297909591497434, 0.9250349988350575], 'Confusion_Matrix': [array([[398,  11,   0],\n",
      "       [ 35,  52,   0],\n",
      "       [  0,   3,   0]]), array([[397,  12,   0],\n",
      "       [ 38,  49,   0],\n",
      "       [  0,   3,   0]]), array([[401,   8,   0],\n",
      "       [ 37,  50,   0],\n",
      "       [  0,   3,   0]]), array([[401,   8,   0],\n",
      "       [ 37,  50,   0],\n",
      "       [  0,   3,   0]]), array([[398,  11,   0],\n",
      "       [ 41,  46,   0],\n",
      "       [  0,   3,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.97      0.95       409\\n         1.0       0.79      0.60      0.68        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       499\\n   macro avg       0.57      0.52      0.54       499\\nweighted avg       0.89      0.90      0.89       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.97      0.94       409\\n         1.0       0.77      0.56      0.65        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.89       499\\n   macro avg       0.56      0.51      0.53       499\\nweighted avg       0.88      0.89      0.88       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.98      0.95       409\\n         1.0       0.82      0.57      0.68        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       499\\n   macro avg       0.58      0.52      0.54       499\\nweighted avg       0.89      0.90      0.89       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.98      0.95       409\\n         1.0       0.82      0.57      0.68        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.90       499\\n   macro avg       0.58      0.52      0.54       499\\nweighted avg       0.89      0.90      0.89       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.97      0.94       409\\n         1.0       0.77      0.53      0.63        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.89       499\\n   macro avg       0.56      0.50      0.52       499\\nweighted avg       0.88      0.89      0.88       499\\n']}, 'CNN_LSTM (Test)': {'Accuracy': [0.8196392785571143, 0.811623246492986, 0.8196392785571143, 0.8296593186372746, 0.8276553106212425], 'Precision': [0.7710662414976704, 0.7586237078342308, 0.7665454620581369, 0.816406963587038, 0.7928491558686731], 'Recall': [0.8196392785571143, 0.811623246492986, 0.8196392785571143, 0.8296593186372746, 0.8276553106212425], 'F1_Score': [0.771569854974928, 0.768472716183355, 0.7612924033993963, 0.7675686467484469, 0.7744698766683089], 'AUC_ROC': [0.7686257436751222, 0.7774251690910094, 0.7862245979937046, 0.7803870346392754, 0.7757211067574826], 'Confusion_Matrix': [array([[398,  11,   0],\n",
      "       [ 76,  11,   0],\n",
      "       [  3,   0,   0]]), array([[393,  16,   0],\n",
      "       [ 75,  12,   0],\n",
      "       [  3,   0,   0]]), array([[402,   7,   0],\n",
      "       [ 80,   7,   0],\n",
      "       [  3,   0,   0]]), array([[407,   2,   0],\n",
      "       [ 80,   7,   0],\n",
      "       [  3,   0,   0]]), array([[403,   6,   0],\n",
      "       [ 77,  10,   0],\n",
      "       [  3,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.97      0.90       409\\n         1.0       0.50      0.13      0.20        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.82       499\\n   macro avg       0.44      0.37      0.37       499\\nweighted avg       0.77      0.82      0.77       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.96      0.89       409\\n         1.0       0.43      0.14      0.21        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.81       499\\n   macro avg       0.42      0.37      0.37       499\\nweighted avg       0.76      0.81      0.77       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.98      0.90       409\\n         1.0       0.50      0.08      0.14        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.82       499\\n   macro avg       0.44      0.35      0.35       499\\nweighted avg       0.77      0.82      0.76       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      1.00      0.91       409\\n         1.0       0.78      0.08      0.15        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.83       499\\n   macro avg       0.54      0.36      0.35       499\\nweighted avg       0.82      0.83      0.77       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.99      0.90       409\\n         1.0       0.62      0.11      0.19        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.83       499\\n   macro avg       0.49      0.37      0.37       499\\nweighted avg       0.79      0.83      0.77       499\\n']}, 'SVM (Test)': {'Accuracy': [0.280561122244489, 0.8036072144288577, 0.7394789579158316, 0.6092184368737475, 0.7074148296593187], 'Precision': [0.7672948122262782, 0.7113613295067113, 0.6972095191924682, 0.7151505356754565, 0.6985947799212884], 'Recall': [0.280561122244489, 0.8036072144288577, 0.7394789579158316, 0.6092184368737475, 0.7074148296593187], 'F1_Score': [0.3936055455028338, 0.7409652607133486, 0.7165954931306051, 0.6565565649064627, 0.702960255377046], 'AUC_ROC': [0.5853218616653566, 0.49592739913135236, 0.47258666687866463, 0.5173577794660901, 0.47622974138414975], 'Confusion_Matrix': [array([[117,  82, 210],\n",
      "       [ 14,  21,  52],\n",
      "       [  0,   1,   2]]), array([[398,  11,   0],\n",
      "       [ 83,   3,   1],\n",
      "       [  3,   0,   0]]), array([[360,  49,   0],\n",
      "       [ 78,   9,   0],\n",
      "       [  2,   1,   0]]), array([[285,  90,  34],\n",
      "       [ 54,  19,  14],\n",
      "       [  2,   1,   0]]), array([[339,  70,   0],\n",
      "       [ 73,  14,   0],\n",
      "       [  3,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.29      0.43       409\\n         1.0       0.20      0.24      0.22        87\\n         2.0       0.01      0.67      0.01         3\\n\\n    accuracy                           0.28       499\\n   macro avg       0.37      0.40      0.22       499\\nweighted avg       0.77      0.28      0.39       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.97      0.89       409\\n         1.0       0.21      0.03      0.06        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.80       499\\n   macro avg       0.35      0.34      0.32       499\\nweighted avg       0.71      0.80      0.74       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.88      0.85       409\\n         1.0       0.15      0.10      0.12        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.74       499\\n   macro avg       0.32      0.33      0.32       499\\nweighted avg       0.70      0.74      0.72       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.70      0.76       409\\n         1.0       0.17      0.22      0.19        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.61       499\\n   macro avg       0.34      0.31      0.32       499\\nweighted avg       0.72      0.61      0.66       499\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.83      0.82       409\\n         1.0       0.17      0.16      0.16        87\\n         2.0       0.00      0.00      0.00         3\\n\\n    accuracy                           0.71       499\\n   macro avg       0.33      0.33      0.33       499\\nweighted avg       0.70      0.71      0.70       499\\n']}}\n",
      "------------------------------------------------------------------\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "------------------------------------------------------------------\n",
      "ID value MMCS0003\n",
      "{'LSTM (Validation)': {'Accuracy': [0.8651685393258427, 0.898876404494382, 0.8985915492957747, 0.8788732394366198, 0.8704225352112676], 'Precision': [0.8257138820557143, 0.8663261341190946, 0.8122861462560675, 0.831686501437566, 0.8320037086423867], 'Recall': [0.8651685393258427, 0.898876404494382, 0.8985915492957747, 0.8788732394366198, 0.8704225352112676], 'F1_Score': [0.8436774700317613, 0.869900523253622, 0.8532620052660174, 0.8492747241711617, 0.8486431887051561], 'AUC_ROC': [0.8033373051030144, 0.8492519302577222, 0.8382493153121169, 0.8276557153656401, 0.7941932243176573], 'Confusion_Matrix': [array([[306,  13,   1],\n",
      "       [ 31,   2,   1],\n",
      "       [  1,   1,   0]]), array([[316,   4,   0],\n",
      "       [ 29,   4,   1],\n",
      "       [  2,   0,   0]]), array([[319,   1,   0],\n",
      "       [ 34,   0,   0],\n",
      "       [  1,   0,   0]]), array([[310,   7,   2],\n",
      "       [ 33,   2,   0],\n",
      "       [  1,   0,   0]]), array([[306,  12,   1],\n",
      "       [ 32,   3,   0],\n",
      "       [  0,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.96      0.93       320\\n         1.0       0.12      0.06      0.08        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.87       356\\n   macro avg       0.34      0.34      0.34       356\\nweighted avg       0.83      0.87      0.84       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.99      0.95       320\\n         1.0       0.50      0.12      0.19        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       356\\n   macro avg       0.47      0.37      0.38       356\\nweighted avg       0.87      0.90      0.87       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       320\\n         1.0       0.00      0.00      0.00        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.90       355\\n   macro avg       0.30      0.33      0.32       355\\nweighted avg       0.81      0.90      0.85       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.97      0.94       319\\n         1.0       0.22      0.06      0.09        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.88       355\\n   macro avg       0.37      0.34      0.34       355\\nweighted avg       0.83      0.88      0.85       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.96      0.93       319\\n         1.0       0.19      0.09      0.12        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.87       355\\n   macro avg       0.36      0.35      0.35       355\\nweighted avg       0.83      0.87      0.85       355\\n']}, 'Transformer (Validation)': {'Accuracy': [0.8932584269662921, 0.8623595505617978, 0.8929577464788733, 0.9126760563380282, 0.8647887323943662], 'Precision': [0.8866300673271835, 0.8998211128706566, 0.888954279033887, 0.9088972169096676, 0.8762007945106537], 'Recall': [0.8932584269662921, 0.8623595505617978, 0.8929577464788733, 0.9126760563380282, 0.8647887323943662], 'F1_Score': [0.8899162773860264, 0.8775519733166728, 0.8909382271215986, 0.9107668656868748, 0.8700722995225351], 'AUC_ROC': [0.8373803745883496, 0.8681871647833617, 0.8770235776558076, 0.8724463956526353, 0.8186360109811411], 'Confusion_Matrix': [array([[303,  17,   0],\n",
      "       [ 19,  15,   0],\n",
      "       [  1,   1,   0]]), array([[286,  32,   2],\n",
      "       [ 11,  21,   2],\n",
      "       [  1,   1,   0]]), array([[302,  18,   0],\n",
      "       [ 19,  15,   0],\n",
      "       [  1,   0,   0]]), array([[305,  14,   0],\n",
      "       [ 16,  19,   0],\n",
      "       [  0,   1,   0]]), array([[292,  27,   0],\n",
      "       [ 19,  15,   1],\n",
      "       [  1,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.95      0.94       320\\n         1.0       0.45      0.44      0.45        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       356\\n   macro avg       0.46      0.46      0.46       356\\nweighted avg       0.89      0.89      0.89       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.96      0.89      0.93       320\\n         1.0       0.39      0.62      0.48        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.86       356\\n   macro avg       0.45      0.50      0.47       356\\nweighted avg       0.90      0.86      0.88       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.94      0.94       320\\n         1.0       0.45      0.44      0.45        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.89       355\\n   macro avg       0.46      0.46      0.46       355\\nweighted avg       0.89      0.89      0.89       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.95      0.96      0.95       319\\n         1.0       0.56      0.54      0.55        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.91       355\\n   macro avg       0.50      0.50      0.50       355\\nweighted avg       0.91      0.91      0.91       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.92      0.93       319\\n         1.0       0.36      0.43      0.39        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.86       355\\n   macro avg       0.43      0.45      0.44       355\\nweighted avg       0.88      0.86      0.87       355\\n']}, 'XGBoost (Validation)': {'Accuracy': [0.9213483146067416, 0.9213483146067416, 0.952112676056338, 0.9323943661971831, 0.9295774647887324], 'Precision': [0.9061993403767679, 0.9037301718440186, 0.9517114556776863, 0.9266061722051632, 0.9287249814677538], 'Recall': [0.9213483146067416, 0.9213483146067416, 0.952112676056338, 0.9323943661971831, 0.9295774647887324], 'F1_Score': [0.9104445258832429, 0.9054885938032006, 0.944389861001862, 0.9216209074333432, 0.9135716218967004], 'AUC_ROC': [0.9225407655106346, 0.9013442541228139, 0.9356480442398835, 0.9158313771517997, 0.9242908841940533], 'Confusion_Matrix': [array([[314,   6,   0],\n",
      "       [ 20,  14,   0],\n",
      "       [  1,   1,   0]]), array([[317,   3,   0],\n",
      "       [ 23,  11,   0],\n",
      "       [  0,   2,   0]]), array([[320,   0,   0],\n",
      "       [ 16,  18,   0],\n",
      "       [  1,   0,   0]]), array([[316,   3,   0],\n",
      "       [ 21,  14,   0],\n",
      "       [  0,   0,   1]]), array([[318,   1,   0],\n",
      "       [ 24,  11,   0],\n",
      "       [  0,   0,   1]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.98      0.96       320\\n         1.0       0.67      0.41      0.51        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       356\\n   macro avg       0.53      0.46      0.49       356\\nweighted avg       0.91      0.92      0.91       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.99      0.96       320\\n         1.0       0.69      0.32      0.44        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       356\\n   macro avg       0.54      0.44      0.47       356\\nweighted avg       0.90      0.92      0.91       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.95      1.00      0.97       320\\n         1.0       1.00      0.53      0.69        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.95       355\\n   macro avg       0.65      0.51      0.56       355\\nweighted avg       0.95      0.95      0.94       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.99      0.96       319\\n         1.0       0.82      0.40      0.54        35\\n         2.0       1.00      1.00      1.00         1\\n\\n    accuracy                           0.93       355\\n   macro avg       0.92      0.80      0.83       355\\nweighted avg       0.93      0.93      0.92       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      1.00      0.96       319\\n         1.0       0.92      0.31      0.47        35\\n         2.0       1.00      1.00      1.00         1\\n\\n    accuracy                           0.93       355\\n   macro avg       0.95      0.77      0.81       355\\nweighted avg       0.93      0.93      0.91       355\\n']}, 'DecisionTree (Validation)': {'Accuracy': [0.8904494382022472, 0.8904494382022472, 0.9014084507042254, 0.8619718309859155, 0.8760563380281691], 'Precision': [0.8862846173465964, 0.8945986455586796, 0.8962717481358741, 0.879253840193263, 0.8760563380281691], 'Recall': [0.8904494382022472, 0.8904494382022472, 0.9014084507042254, 0.8619718309859155, 0.8760563380281691], 'F1_Score': [0.887784679089027, 0.8922686135739476, 0.8987788648095748, 0.8694484451585017, 0.8760563380281691], 'AUC_ROC': [0.680383022774327, 0.729867763858184, 0.7036493101913662, 0.6896863229755179, 0.6600694444444444], 'Confusion_Matrix': [array([[303,  17,   0],\n",
      "       [ 21,  13,   0],\n",
      "       [  0,   1,   1]]), array([[299,  20,   1],\n",
      "       [ 16,  18,   0],\n",
      "       [  1,   1,   0]]), array([[304,  16,   0],\n",
      "       [ 18,  16,   0],\n",
      "       [  1,   0,   0]]), array([[290,  27,   2],\n",
      "       [ 19,  15,   1],\n",
      "       [  0,   0,   1]]), array([[297,  22,   0],\n",
      "       [ 22,  13,   0],\n",
      "       [  0,   0,   1]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.95      0.94       320\\n         1.0       0.42      0.38      0.40        34\\n         2.0       1.00      0.50      0.67         2\\n\\n    accuracy                           0.89       356\\n   macro avg       0.78      0.61      0.67       356\\nweighted avg       0.89      0.89      0.89       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.95      0.93      0.94       320\\n         1.0       0.46      0.53      0.49        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       356\\n   macro avg       0.47      0.49      0.48       356\\nweighted avg       0.89      0.89      0.89       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.95      0.95       320\\n         1.0       0.50      0.47      0.48        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.90       355\\n   macro avg       0.48      0.47      0.48       355\\nweighted avg       0.90      0.90      0.90       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.91      0.92       319\\n         1.0       0.36      0.43      0.39        35\\n         2.0       0.25      1.00      0.40         1\\n\\n    accuracy                           0.86       355\\n   macro avg       0.52      0.78      0.57       355\\nweighted avg       0.88      0.86      0.87       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.93      0.93       319\\n         1.0       0.37      0.37      0.37        35\\n         2.0       1.00      1.00      1.00         1\\n\\n    accuracy                           0.88       355\\n   macro avg       0.77      0.77      0.77       355\\nweighted avg       0.88      0.88      0.88       355\\n']}, 'RandomForest (Validation)': {'Accuracy': [0.9185393258426966, 0.9129213483146067, 0.9408450704225352, 0.9098591549295775, 0.9183098591549296], 'Precision': [0.9112384735219304, 0.901417870518994, 0.9416711412168023, 0.8920718513982445, 0.9223004694835679], 'Recall': [0.9185393258426966, 0.9129213483146067, 0.9408450704225352, 0.9098591549295775, 0.9183098591549296], 'F1_Score': [0.8953317958214517, 0.8825046117725978, 0.9286392079151662, 0.8859588589098177, 0.8923862012655644], 'AUC_ROC': [0.9053476077184812, 0.9200181841205703, 0.9321447689250769, 0.9018363654147105, 0.9248845852895147], 'Confusion_Matrix': [array([[319,   1,   0],\n",
      "       [ 26,   8,   0],\n",
      "       [  2,   0,   0]]), array([[320,   0,   0],\n",
      "       [ 29,   5,   0],\n",
      "       [  1,   1,   0]]), array([[320,   0,   0],\n",
      "       [ 20,  14,   0],\n",
      "       [  1,   0,   0]]), array([[316,   3,   0],\n",
      "       [ 28,   7,   0],\n",
      "       [  1,   0,   0]]), array([[319,   0,   0],\n",
      "       [ 28,   7,   0],\n",
      "       [  1,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       320\\n         1.0       0.89      0.24      0.37        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       356\\n   macro avg       0.60      0.41      0.44       356\\nweighted avg       0.91      0.92      0.90       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      1.00      0.96       320\\n         1.0       0.83      0.15      0.25        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       356\\n   macro avg       0.58      0.38      0.40       356\\nweighted avg       0.90      0.91      0.88       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      1.00      0.97       320\\n         1.0       1.00      0.41      0.58        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.94       355\\n   macro avg       0.65      0.47      0.52       355\\nweighted avg       0.94      0.94      0.93       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.99      0.95       319\\n         1.0       0.70      0.20      0.31        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.91       355\\n   macro avg       0.54      0.40      0.42       355\\nweighted avg       0.89      0.91      0.89       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       319\\n         1.0       1.00      0.20      0.33        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.92       355\\n   macro avg       0.64      0.40      0.43       355\\nweighted avg       0.92      0.92      0.89       355\\n']}, 'CNN_LSTM (Validation)': {'Accuracy': [0.898876404494382, 0.8960674157303371, 0.9014084507042254, 0.8985915492957747, 0.895774647887324], 'Precision': [0.8079787905567479, 0.8077227409400222, 0.8125371950009919, 0.8074667724657806, 0.807209357841967], 'Recall': [0.898876404494382, 0.8960674157303371, 0.9014084507042254, 0.8985915492957747, 0.895774647887324], 'F1_Score': [0.8510072468585864, 0.8496046608406159, 0.8546687532603026, 0.8505955614995611, 0.8491890421279535], 'AUC_ROC': [0.7722451918192585, 0.8258174705688842, 0.8445553239177396, 0.6637292943158006, 0.768358216625554], 'Confusion_Matrix': [array([[320,   0,   0],\n",
      "       [ 34,   0,   0],\n",
      "       [  2,   0,   0]]), array([[319,   1,   0],\n",
      "       [ 34,   0,   0],\n",
      "       [  2,   0,   0]]), array([[320,   0,   0],\n",
      "       [ 34,   0,   0],\n",
      "       [  1,   0,   0]]), array([[319,   0,   0],\n",
      "       [ 35,   0,   0],\n",
      "       [  1,   0,   0]]), array([[318,   1,   0],\n",
      "       [ 35,   0,   0],\n",
      "       [  1,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       320\\n         1.0       0.00      0.00      0.00        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       356\\n   macro avg       0.30      0.33      0.32       356\\nweighted avg       0.81      0.90      0.85       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       320\\n         1.0       0.00      0.00      0.00        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       356\\n   macro avg       0.30      0.33      0.32       356\\nweighted avg       0.81      0.90      0.85       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       320\\n         1.0       0.00      0.00      0.00        34\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.90       355\\n   macro avg       0.30      0.33      0.32       355\\nweighted avg       0.81      0.90      0.85       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       319\\n         1.0       0.00      0.00      0.00        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.90       355\\n   macro avg       0.30      0.33      0.32       355\\nweighted avg       0.81      0.90      0.85       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       319\\n         1.0       0.00      0.00      0.00        35\\n         2.0       0.00      0.00      0.00         1\\n\\n    accuracy                           0.90       355\\n   macro avg       0.30      0.33      0.32       355\\nweighted avg       0.81      0.90      0.85       355\\n']}, 'SVM (Validation)': {'Accuracy': [0.8398876404494382, 0.8792134831460674, 0.8760563380281691, 0.8676056338028169, 0.8450704225352113], 'Precision': [0.853608470181504, 0.8770287141073658, 0.891797117012928, 0.8884585289514867, 0.8559088124223343], 'Recall': [0.8398876404494382, 0.8792134831460674, 0.8760563380281691, 0.8676056338028169, 0.8450704225352113], 'F1_Score': [0.8461666101404403, 0.8780898876404495, 0.8830177647079056, 0.876596965891736, 0.8498679728043251], 'AUC_ROC': [0.7787101152246921, 0.8263177614201851, 0.8366778866344483, 0.8131767061881648, 0.8127816901408451], 'Confusion_Matrix': [array([[288,  32,   0],\n",
      "       [ 23,  11,   0],\n",
      "       [  1,   1,   0]]), array([[299,  21,   0],\n",
      "       [ 20,  14,   0],\n",
      "       [  1,   1,   0]]), array([[293,  27,   0],\n",
      "       [ 17,  17,   0],\n",
      "       [  0,   0,   1]]), array([[289,  30,   0],\n",
      "       [ 17,  18,   0],\n",
      "       [  0,   0,   1]]), array([[289,  29,   1],\n",
      "       [ 24,  10,   1],\n",
      "       [  0,   0,   1]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.90      0.91       320\\n         1.0       0.25      0.32      0.28        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.84       356\\n   macro avg       0.39      0.41      0.40       356\\nweighted avg       0.85      0.84      0.85       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.93      0.93       320\\n         1.0       0.39      0.41      0.40        34\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.88       356\\n   macro avg       0.44      0.45      0.44       356\\nweighted avg       0.88      0.88      0.88       356\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.95      0.92      0.93       320\\n         1.0       0.39      0.50      0.44        34\\n         2.0       1.00      1.00      1.00         1\\n\\n    accuracy                           0.88       355\\n   macro avg       0.78      0.81      0.79       355\\nweighted avg       0.89      0.88      0.88       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.91      0.92       319\\n         1.0       0.38      0.51      0.43        35\\n         2.0       1.00      1.00      1.00         1\\n\\n    accuracy                           0.87       355\\n   macro avg       0.77      0.81      0.79       355\\nweighted avg       0.89      0.87      0.88       355\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.91      0.91       319\\n         1.0       0.26      0.29      0.27        35\\n         2.0       0.33      1.00      0.50         1\\n\\n    accuracy                           0.85       355\\n   macro avg       0.50      0.73      0.56       355\\nweighted avg       0.86      0.85      0.85       355\\n']}, 'LSTM (Test)': {'Accuracy': [0.8674157303370786, 0.8898876404494382, 0.8966292134831461, 0.8741573033707866, 0.8764044943820225], 'Precision': [0.8464810291483471, 0.8553055759739578, 0.835388162755739, 0.8390082305932175, 0.850422032125714], 'Recall': [0.8674157303370786, 0.8898876404494382, 0.8966292134831461, 0.8741573033707866, 0.8764044943820225], 'F1_Score': [0.8560077056921754, 0.8664210267747483, 0.8548914509581418, 0.8539039994812073, 0.8612485847119026], 'AUC_ROC': [0.8008483659432987, 0.7723831708460849, 0.7387750432911658, 0.7565286123385826, 0.7831839736059855], 'Confusion_Matrix': [array([[378,  21,   1],\n",
      "       [ 35,   8,   0],\n",
      "       [  1,   1,   0]]), array([[390,   9,   1],\n",
      "       [ 37,   6,   0],\n",
      "       [  1,   1,   0]]), array([[398,   2,   0],\n",
      "       [ 42,   1,   0],\n",
      "       [  1,   1,   0]]), array([[384,  15,   1],\n",
      "       [ 38,   5,   0],\n",
      "       [  1,   1,   0]]), array([[382,  17,   1],\n",
      "       [ 35,   8,   0],\n",
      "       [  2,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.94      0.93       400\\n         1.0       0.27      0.19      0.22        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.87       445\\n   macro avg       0.39      0.38      0.38       445\\nweighted avg       0.85      0.87      0.86       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.97      0.94       400\\n         1.0       0.38      0.14      0.20        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       445\\n   macro avg       0.43      0.37      0.38       445\\nweighted avg       0.86      0.89      0.87       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.99      0.95       400\\n         1.0       0.25      0.02      0.04        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.38      0.34      0.33       445\\nweighted avg       0.84      0.90      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.96      0.93       400\\n         1.0       0.24      0.12      0.16        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.87       445\\n   macro avg       0.38      0.36      0.36       445\\nweighted avg       0.84      0.87      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.95      0.93       400\\n         1.0       0.32      0.19      0.24        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.88       445\\n   macro avg       0.41      0.38      0.39       445\\nweighted avg       0.85      0.88      0.86       445\\n']}, 'Transformer (Test)': {'Accuracy': [0.9011235955056179, 0.8426966292134831, 0.8651685393258427, 0.9056179775280899, 0.8853932584269663], 'Precision': [0.8946616176953255, 0.8816122703763154, 0.8728573282222822, 0.8995525696718754, 0.905762850570645], 'Recall': [0.9011235955056179, 0.8426966292134831, 0.8651685393258427, 0.9056179775280899, 0.8853932584269663], 'F1_Score': [0.8974607584009706, 0.8599506247136302, 0.8686164793510336, 0.9025354767095503, 0.8930531284659836], 'AUC_ROC': [0.855597397899033, 0.7850823506935861, 0.8495065200371776, 0.8074728773259024, 0.8622649663729779], 'Confusion_Matrix': [array([[382,  16,   2],\n",
      "       [ 24,  19,   0],\n",
      "       [  1,   1,   0]]), array([[355,  41,   4],\n",
      "       [ 20,  20,   3],\n",
      "       [  0,   2,   0]]), array([[367,  33,   0],\n",
      "       [ 25,  18,   0],\n",
      "       [  1,   1,   0]]), array([[381,  19,   0],\n",
      "       [ 21,  22,   0],\n",
      "       [  2,   0,   0]]), array([[366,  34,   0],\n",
      "       [ 15,  28,   0],\n",
      "       [  0,   2,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.95      0.95       400\\n         1.0       0.53      0.44      0.48        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.49      0.47      0.48       445\\nweighted avg       0.89      0.90      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.95      0.89      0.92       400\\n         1.0       0.32      0.47      0.38        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.84       445\\n   macro avg       0.42      0.45      0.43       445\\nweighted avg       0.88      0.84      0.86       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.92      0.93       400\\n         1.0       0.35      0.42      0.38        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.87       445\\n   macro avg       0.43      0.45      0.43       445\\nweighted avg       0.87      0.87      0.87       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.95      0.95       400\\n         1.0       0.54      0.51      0.52        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       445\\n   macro avg       0.49      0.49      0.49       445\\nweighted avg       0.90      0.91      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.96      0.92      0.94       400\\n         1.0       0.44      0.65      0.52        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       445\\n   macro avg       0.47      0.52      0.49       445\\nweighted avg       0.91      0.89      0.89       445\\n']}, 'XGBoost (Test)': {'Accuracy': [0.9146067415730337, 0.9235955056179775, 0.9258426966292135, 0.9146067415730337, 0.9191011235955057], 'Precision': [0.8973518108302864, 0.9096744419831505, 0.9139715089274064, 0.8982724229191204, 0.9035131264067184], 'Recall': [0.9146067415730337, 0.9235955056179775, 0.9258426966292135, 0.9146067415730337, 0.9191011235955057], 'F1_Score': [0.9016335612444013, 0.9117818917020368, 0.9108091765711511, 0.9030813728419982, 0.9067077264732191], 'AUC_ROC': [0.9335704825691042, 0.904725836076085, 0.9171559522161596, 0.9370723609066378, 0.9149722814138405], 'Confusion_Matrix': [array([[392,   8,   0],\n",
      "       [ 28,  15,   0],\n",
      "       [  1,   1,   0]]), array([[394,   6,   0],\n",
      "       [ 26,  17,   0],\n",
      "       [  1,   1,   0]]), array([[397,   3,   0],\n",
      "       [ 28,  15,   0],\n",
      "       [  1,   1,   0]]), array([[391,   9,   0],\n",
      "       [ 27,  16,   0],\n",
      "       [  1,   1,   0]]), array([[393,   7,   0],\n",
      "       [ 27,  16,   0],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.98      0.95       400\\n         1.0       0.62      0.35      0.45        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       445\\n   macro avg       0.52      0.44      0.47       445\\nweighted avg       0.90      0.91      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.94      0.98      0.96       400\\n         1.0       0.71      0.40      0.51        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.55      0.46      0.49       445\\nweighted avg       0.91      0.92      0.91       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.99      0.96       400\\n         1.0       0.79      0.35      0.48        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.93       445\\n   macro avg       0.57      0.45      0.48       445\\nweighted avg       0.91      0.93      0.91       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.98      0.95       400\\n         1.0       0.62      0.37      0.46        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       445\\n   macro avg       0.52      0.45      0.47       445\\nweighted avg       0.90      0.91      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.98      0.96       400\\n         1.0       0.67      0.37      0.48        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.53      0.45      0.48       445\\nweighted avg       0.90      0.92      0.91       445\\n']}, 'DecisionTree (Test)': {'Accuracy': [0.8764044943820225, 0.8584269662921349, 0.8764044943820225, 0.8561797752808988, 0.8606741573033708], 'Precision': [0.8712654497947635, 0.8659976941024097, 0.8710041197174216, 0.8568753344034242, 0.8693312748377505], 'Recall': [0.8764044943820225, 0.8584269662921349, 0.8764044943820225, 0.8561797752808988, 0.8606741573033708], 'F1_Score': [0.8737354608159532, 0.8621157515369937, 0.8736875843149327, 0.8565234633179114, 0.8646830577980471], 'AUC_ROC': [0.6555370251825896, 0.6457018893493405, 0.6454394693200665, 0.6049887881884782, 0.6565827746145121], 'Confusion_Matrix': [array([[376,  24,   0],\n",
      "       [ 27,  14,   2],\n",
      "       [  1,   1,   0]]), array([[367,  31,   2],\n",
      "       [ 27,  15,   1],\n",
      "       [  1,   1,   0]]), array([[374,  26,   0],\n",
      "       [ 27,  16,   0],\n",
      "       [  2,   0,   0]]), array([[368,  29,   3],\n",
      "       [ 30,  13,   0],\n",
      "       [  2,   0,   0]]), array([[366,  33,   1],\n",
      "       [ 26,  17,   0],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.94      0.94       400\\n         1.0       0.36      0.33      0.34        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.88       445\\n   macro avg       0.43      0.42      0.43       445\\nweighted avg       0.87      0.88      0.87       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.92      0.92       400\\n         1.0       0.32      0.35      0.33        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.86       445\\n   macro avg       0.42      0.42      0.42       445\\nweighted avg       0.87      0.86      0.86       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.94      0.93       400\\n         1.0       0.38      0.37      0.38        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.88       445\\n   macro avg       0.44      0.44      0.44       445\\nweighted avg       0.87      0.88      0.87       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.92      0.92       400\\n         1.0       0.31      0.30      0.31        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.86       445\\n   macro avg       0.41      0.41      0.41       445\\nweighted avg       0.86      0.86      0.86       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.92      0.92       400\\n         1.0       0.33      0.40      0.36        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.86       445\\n   macro avg       0.42      0.44      0.43       445\\nweighted avg       0.87      0.86      0.86       445\\n']}, 'RandomForest (Test)': {'Accuracy': [0.9213483146067416, 0.9213483146067416, 0.9191011235955057, 0.9146067415730337, 0.9213483146067416], 'Precision': [0.9119754153462019, 0.9168716644609943, 0.9088192300040654, 0.8986908685159717, 0.9119754153462019], 'Recall': [0.9213483146067416, 0.9213483146067416, 0.9191011235955057, 0.9146067415730337, 0.9213483146067416], 'F1_Score': [0.9001049512285467, 0.8997601737324143, 0.8962463841512089, 0.8905744279325621, 0.9001049512285467], 'AUC_ROC': [0.9400366098422928, 0.9042546207422995, 0.9215090684839765, 0.9165735500177692, 0.9219138588135742], 'Confusion_Matrix': [array([[399,   1,   0],\n",
      "       [ 32,  11,   0],\n",
      "       [  1,   1,   0]]), array([[399,   1,   0],\n",
      "       [ 32,  11,   0],\n",
      "       [  2,   0,   0]]), array([[399,   1,   0],\n",
      "       [ 33,  10,   0],\n",
      "       [  1,   1,   0]]), array([[398,   2,   0],\n",
      "       [ 34,   9,   0],\n",
      "       [  1,   1,   0]]), array([[399,   1,   0],\n",
      "       [ 32,  11,   0],\n",
      "       [  1,   1,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       400\\n         1.0       0.85      0.26      0.39        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.59      0.42      0.45       445\\nweighted avg       0.91      0.92      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       400\\n         1.0       0.92      0.26      0.40        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.61      0.42      0.45       445\\nweighted avg       0.92      0.92      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       400\\n         1.0       0.83      0.23      0.36        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.58      0.41      0.44       445\\nweighted avg       0.91      0.92      0.90       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.99      0.96       400\\n         1.0       0.75      0.21      0.33        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.91       445\\n   macro avg       0.56      0.40      0.43       445\\nweighted avg       0.90      0.91      0.89       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.92      1.00      0.96       400\\n         1.0       0.85      0.26      0.39        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.92       445\\n   macro avg       0.59      0.42      0.45       445\\nweighted avg       0.91      0.92      0.90       445\\n']}, 'CNN_LSTM (Test)': {'Accuracy': [0.898876404494382, 0.8943820224719101, 0.898876404494382, 0.898876404494382, 0.8966292134831461], 'Precision': [0.8079787905567478, 0.8075684175818602, 0.8079787905567478, 0.8079787905567478, 0.8077740662010325], 'Recall': [0.898876404494382, 0.8943820224719101, 0.898876404494382, 0.898876404494382, 0.8966292134831461], 'F1_Score': [0.8510072468585865, 0.8487611126661067, 0.8510072468585865, 0.8510072468585865, 0.8498855104105651], 'AUC_ROC': [0.7611970662997858, 0.7745045185213508, 0.7736219095592455, 0.588019718285333, 0.7462532574317816], 'Confusion_Matrix': [array([[400,   0,   0],\n",
      "       [ 43,   0,   0],\n",
      "       [  2,   0,   0]]), array([[398,   2,   0],\n",
      "       [ 43,   0,   0],\n",
      "       [  2,   0,   0]]), array([[400,   0,   0],\n",
      "       [ 43,   0,   0],\n",
      "       [  2,   0,   0]]), array([[400,   0,   0],\n",
      "       [ 43,   0,   0],\n",
      "       [  2,   0,   0]]), array([[399,   1,   0],\n",
      "       [ 43,   0,   0],\n",
      "       [  2,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.30      0.33      0.32       445\\nweighted avg       0.81      0.90      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.99      0.94       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.89       445\\n   macro avg       0.30      0.33      0.31       445\\nweighted avg       0.81      0.89      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.30      0.33      0.32       445\\nweighted avg       0.81      0.90      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.30      0.33      0.32       445\\nweighted avg       0.81      0.90      0.85       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.90      1.00      0.95       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.90       445\\n   macro avg       0.30      0.33      0.32       445\\nweighted avg       0.81      0.90      0.85       445\\n']}, 'SVM (Test)': {'Accuracy': [0.32808988764044944, 0.5235955056179775, 0.7101123595505618, 0.4696629213483146, 0.49887640449438203], 'Precision': [0.7622215411680463, 0.8006329078990219, 0.8093365436062064, 0.8063008180807476, 0.7821944821570086], 'Recall': [0.32808988764044944, 0.5235955056179775, 0.7101123595505618, 0.4696629213483146, 0.49887640449438203], 'F1_Score': [0.4565547348917486, 0.6188472742405325, 0.7563600444499321, 0.5701120458431148, 0.6033052197520526], 'AUC_ROC': [0.4216915898185116, 0.45097449740332923, 0.44081278745895647, 0.44617230760999566, 0.403046081216242], 'Confusion_Matrix': [array([[145,   0, 255],\n",
      "       [ 25,   0,  18],\n",
      "       [  1,   0,   1]]), array([[219, 181,   0],\n",
      "       [ 29,  14,   0],\n",
      "       [  0,   2,   0]]), array([[312,  44,  44],\n",
      "       [ 36,   4,   3],\n",
      "       [  2,   0,   0]]), array([[190, 203,   7],\n",
      "       [ 23,  19,   1],\n",
      "       [  1,   1,   0]]), array([[214, 110,  76],\n",
      "       [ 32,   8,   3],\n",
      "       [  2,   0,   0]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.36      0.51       400\\n         1.0       0.00      0.00      0.00        43\\n         2.0       0.00      0.50      0.01         2\\n\\n    accuracy                           0.33       445\\n   macro avg       0.28      0.29      0.17       445\\nweighted avg       0.76      0.33      0.46       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.55      0.68       400\\n         1.0       0.07      0.33      0.12        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.52       445\\n   macro avg       0.32      0.29      0.26       445\\nweighted avg       0.80      0.52      0.62       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.78      0.83       400\\n         1.0       0.08      0.09      0.09        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.71       445\\n   macro avg       0.32      0.29      0.31       445\\nweighted avg       0.81      0.71      0.76       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.47      0.62       400\\n         1.0       0.09      0.44      0.14        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.47       445\\n   macro avg       0.32      0.31      0.25       445\\nweighted avg       0.81      0.47      0.57       445\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.54      0.66       400\\n         1.0       0.07      0.19      0.10        43\\n         2.0       0.00      0.00      0.00         2\\n\\n    accuracy                           0.50       445\\n   macro avg       0.31      0.24      0.25       445\\nweighted avg       0.78      0.50      0.60       445\\n']}}\n",
      "------------------------------------------------------------------\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "------------------------------------------------------------------\n",
      "ID value MMCS0005\n",
      "{'LSTM (Validation)': {'Accuracy': [0.6851851851851852, 0.7345679012345679, 0.6882716049382716, 0.6944444444444444, 0.6759259259259259], 'Precision': [0.6841962738735275, 0.7312500000000001, 0.685213529856387, 0.6880198198332955, 0.6841445532377844], 'Recall': [0.6851851851851852, 0.7345679012345679, 0.6882716049382716, 0.6944444444444444, 0.6759259259259259], 'F1_Score': [0.6845805006448958, 0.7322727569641151, 0.6861910414688193, 0.6896789740992639, 0.6785093229906406], 'AUC_ROC': [0.8196172968335251, 0.8323960636907956, 0.8296334200945411, 0.8057706499711659, 0.8102204826390857], 'Confusion_Matrix': [array([[145,  40,   3],\n",
      "       [ 41,  68,   8],\n",
      "       [  5,   5,   9]]), array([[152,  35,   1],\n",
      "       [ 32,  79,   6],\n",
      "       [  6,   6,   7]]), array([[148,  35,   5],\n",
      "       [ 45,  66,   6],\n",
      "       [  3,   7,   9]]), array([[153,  31,   4],\n",
      "       [ 45,  65,   7],\n",
      "       [  5,   7,   7]]), array([[143,  37,   7],\n",
      "       [ 40,  66,  12],\n",
      "       [  4,   5,  10]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.77      0.77       188\\n         1.0       0.60      0.58      0.59       117\\n         2.0       0.45      0.47      0.46        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.60      0.61      0.61       324\\nweighted avg       0.68      0.69      0.68       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.81      0.80       188\\n         1.0       0.66      0.68      0.67       117\\n         2.0       0.50      0.37      0.42        19\\n\\n    accuracy                           0.73       324\\n   macro avg       0.65      0.62      0.63       324\\nweighted avg       0.73      0.73      0.73       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.79      0.77       188\\n         1.0       0.61      0.56      0.59       117\\n         2.0       0.45      0.47      0.46        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.61      0.61      0.61       324\\nweighted avg       0.69      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.75      0.81      0.78       188\\n         1.0       0.63      0.56      0.59       117\\n         2.0       0.39      0.37      0.38        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.59      0.58      0.58       324\\nweighted avg       0.69      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.76      0.76       187\\n         1.0       0.61      0.56      0.58       118\\n         2.0       0.34      0.53      0.42        19\\n\\n    accuracy                           0.68       324\\n   macro avg       0.57      0.62      0.59       324\\nweighted avg       0.68      0.68      0.68       324\\n']}, 'Transformer (Validation)': {'Accuracy': [0.7160493827160493, 0.691358024691358, 0.7530864197530864, 0.7376543209876543, 0.7438271604938271], 'Precision': [0.7075519446168724, 0.70744301994302, 0.7510336047355226, 0.7238970989341854, 0.7374994087318482], 'Recall': [0.7160493827160493, 0.691358024691358, 0.7530864197530864, 0.7376543209876543, 0.7438271604938271], 'F1_Score': [0.7111820279261782, 0.6899214883085851, 0.7516092023874998, 0.7261252525219016, 0.7376725398436765], 'AUC_ROC': [0.8277487635571756, 0.8069555640401581, 0.8521116347524258, 0.8505128951939794, 0.8242658455165324], 'Confusion_Matrix': [array([[153,  32,   3],\n",
      "       [ 36,  75,   6],\n",
      "       [  4,  11,   4]]), array([[129,  56,   3],\n",
      "       [ 19,  92,   6],\n",
      "       [  8,   8,   3]]), array([[155,  30,   3],\n",
      "       [ 30,  82,   5],\n",
      "       [  2,  10,   7]]), array([[166,  18,   4],\n",
      "       [ 44,  69,   4],\n",
      "       [  4,  11,   4]]), array([[158,  27,   2],\n",
      "       [ 39,  77,   2],\n",
      "       [  1,  12,   6]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.79      0.81      0.80       188\\n         1.0       0.64      0.64      0.64       117\\n         2.0       0.31      0.21      0.25        19\\n\\n    accuracy                           0.72       324\\n   macro avg       0.58      0.56      0.56       324\\nweighted avg       0.71      0.72      0.71       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.69      0.75       188\\n         1.0       0.59      0.79      0.67       117\\n         2.0       0.25      0.16      0.19        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.56      0.54      0.54       324\\nweighted avg       0.71      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.82      0.83       188\\n         1.0       0.67      0.70      0.69       117\\n         2.0       0.47      0.37      0.41        19\\n\\n    accuracy                           0.75       324\\n   macro avg       0.66      0.63      0.64       324\\nweighted avg       0.75      0.75      0.75       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.88      0.83       188\\n         1.0       0.70      0.59      0.64       117\\n         2.0       0.33      0.21      0.26        19\\n\\n    accuracy                           0.74       324\\n   macro avg       0.60      0.56      0.58       324\\nweighted avg       0.72      0.74      0.73       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.84      0.82       187\\n         1.0       0.66      0.65      0.66       118\\n         2.0       0.60      0.32      0.41        19\\n\\n    accuracy                           0.74       324\\n   macro avg       0.69      0.60      0.63       324\\nweighted avg       0.74      0.74      0.74       324\\n']}, 'XGBoost (Validation)': {'Accuracy': [0.7962962962962963, 0.8117283950617284, 0.8055555555555556, 0.7901234567901234, 0.8209876543209876], 'Precision': [0.794821931371639, 0.8111521438734244, 0.7983327152350118, 0.7874871399176955, 0.823414443792583], 'Recall': [0.7962962962962963, 0.8117283950617284, 0.8055555555555556, 0.7901234567901234, 0.8209876543209876], 'F1_Score': [0.7950422769837983, 0.8085727404718942, 0.8000292388359213, 0.787082446827563, 0.8208461295762883], 'AUC_ROC': [0.9044833248731737, 0.9181834741308623, 0.9310616582867377, 0.9092795897386259, 0.9215635147421882], 'Confusion_Matrix': [array([[163,  25,   0],\n",
      "       [ 27,  85,   5],\n",
      "       [  0,   9,  10]]), array([[167,  21,   0],\n",
      "       [ 28,  87,   2],\n",
      "       [  0,  10,   9]]), array([[170,  18,   0],\n",
      "       [ 28,  84,   5],\n",
      "       [  1,  11,   7]]), array([[163,  25,   0],\n",
      "       [ 28,  85,   4],\n",
      "       [  1,  10,   8]]), array([[161,  26,   0],\n",
      "       [ 21,  94,   3],\n",
      "       [  1,   7,  11]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.87      0.86       188\\n         1.0       0.71      0.73      0.72       117\\n         2.0       0.67      0.53      0.59        19\\n\\n    accuracy                           0.80       324\\n   macro avg       0.75      0.71      0.72       324\\nweighted avg       0.79      0.80      0.80       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.89      0.87       188\\n         1.0       0.74      0.74      0.74       117\\n         2.0       0.82      0.47      0.60        19\\n\\n    accuracy                           0.81       324\\n   macro avg       0.80      0.70      0.74       324\\nweighted avg       0.81      0.81      0.81       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.90      0.88       188\\n         1.0       0.74      0.72      0.73       117\\n         2.0       0.58      0.37      0.45        19\\n\\n    accuracy                           0.81       324\\n   macro avg       0.73      0.66      0.69       324\\nweighted avg       0.80      0.81      0.80       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.87      0.86       188\\n         1.0       0.71      0.73      0.72       117\\n         2.0       0.67      0.42      0.52        19\\n\\n    accuracy                           0.79       324\\n   macro avg       0.74      0.67      0.70       324\\nweighted avg       0.79      0.79      0.79       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.86      0.87       187\\n         1.0       0.74      0.80      0.77       118\\n         2.0       0.79      0.58      0.67        19\\n\\n    accuracy                           0.82       324\\n   macro avg       0.80      0.75      0.77       324\\nweighted avg       0.82      0.82      0.82       324\\n']}, 'DecisionTree (Validation)': {'Accuracy': [0.6975308641975309, 0.6820987654320988, 0.6851851851851852, 0.7129629629629629, 0.6882716049382716], 'Precision': [0.7027469524482667, 0.679812207011071, 0.6946923954767092, 0.7134732481887607, 0.6868849049995622], 'Recall': [0.6975308641975309, 0.6820987654320988, 0.6851851851851852, 0.7129629629629629, 0.6882716049382716], 'F1_Score': [0.699022425387571, 0.6809295576052319, 0.6892543712735312, 0.7131860529849036, 0.6873613445378153], 'AUC_ROC': [0.7244862782366451, 0.7091108455736773, 0.7206446037669048, 0.7395704932008441, 0.7073692654608484], 'Confusion_Matrix': [array([[146,  40,   2],\n",
      "       [ 36,  68,  13],\n",
      "       [  4,   3,  12]]), array([[148,  37,   3],\n",
      "       [ 37,  69,  11],\n",
      "       [  5,  10,   4]]), array([[144,  40,   4],\n",
      "       [ 36,  69,  12],\n",
      "       [  0,  10,   9]]), array([[152,  32,   4],\n",
      "       [ 34,  73,  10],\n",
      "       [  3,  10,   6]]), array([[144,  42,   1],\n",
      "       [ 40,  71,   7],\n",
      "       [  4,   7,   8]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.78      0.78       188\\n         1.0       0.61      0.58      0.60       117\\n         2.0       0.44      0.63      0.52        19\\n\\n    accuracy                           0.70       324\\n   macro avg       0.61      0.66      0.63       324\\nweighted avg       0.70      0.70      0.70       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.79      0.78       188\\n         1.0       0.59      0.59      0.59       117\\n         2.0       0.22      0.21      0.22        19\\n\\n    accuracy                           0.68       324\\n   macro avg       0.53      0.53      0.53       324\\nweighted avg       0.68      0.68      0.68       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.77      0.78       188\\n         1.0       0.58      0.59      0.58       117\\n         2.0       0.36      0.47      0.41        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.58      0.61      0.59       324\\nweighted avg       0.69      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.81      0.81       188\\n         1.0       0.63      0.62      0.63       117\\n         2.0       0.30      0.32      0.31        19\\n\\n    accuracy                           0.71       324\\n   macro avg       0.58      0.58      0.58       324\\nweighted avg       0.71      0.71      0.71       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.77      0.77      0.77       187\\n         1.0       0.59      0.60      0.60       118\\n         2.0       0.50      0.42      0.46        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.62      0.60      0.61       324\\nweighted avg       0.69      0.69      0.69       324\\n']}, 'RandomForest (Validation)': {'Accuracy': [0.7993827160493827, 0.808641975308642, 0.8209876543209876, 0.7808641975308642, 0.8024691358024691], 'Precision': [0.8115379915317492, 0.8185470085470086, 0.8311692541690905, 0.7763069058641975, 0.8101872295102411], 'Recall': [0.7993827160493827, 0.808641975308642, 0.8209876543209876, 0.7808641975308642, 0.8024691358024691], 'F1_Score': [0.7942145067962791, 0.7980339288797924, 0.8128838233557211, 0.7731800097974154, 0.8005187091853757], 'AUC_ROC': [0.9103078711575793, 0.9237097196334192, 0.931505470145903, 0.9090108073146044, 0.9015914371684954], 'Confusion_Matrix': [array([[158,  30,   0],\n",
      "       [ 20,  96,   1],\n",
      "       [  0,  14,   5]]), array([[168,  20,   0],\n",
      "       [ 27,  90,   0],\n",
      "       [  0,  15,   4]]), array([[167,  21,   0],\n",
      "       [ 23,  94,   0],\n",
      "       [  1,  13,   5]]), array([[162,  26,   0],\n",
      "       [ 27,  87,   3],\n",
      "       [  0,  15,   4]]), array([[159,  28,   0],\n",
      "       [ 24,  93,   1],\n",
      "       [  0,  11,   8]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.84      0.86       188\\n         1.0       0.69      0.82      0.75       117\\n         2.0       0.83      0.26      0.40        19\\n\\n    accuracy                           0.80       324\\n   macro avg       0.80      0.64      0.67       324\\nweighted avg       0.81      0.80      0.79       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.89      0.88       188\\n         1.0       0.72      0.77      0.74       117\\n         2.0       1.00      0.21      0.35        19\\n\\n    accuracy                           0.81       324\\n   macro avg       0.86      0.62      0.66       324\\nweighted avg       0.82      0.81      0.80       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.87      0.89      0.88       188\\n         1.0       0.73      0.80      0.77       117\\n         2.0       1.00      0.26      0.42        19\\n\\n    accuracy                           0.82       324\\n   macro avg       0.87      0.65      0.69       324\\nweighted avg       0.83      0.82      0.81       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.86      0.86      0.86       188\\n         1.0       0.68      0.74      0.71       117\\n         2.0       0.57      0.21      0.31        19\\n\\n    accuracy                           0.78       324\\n   macro avg       0.70      0.61      0.63       324\\nweighted avg       0.78      0.78      0.77       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.87      0.85      0.86       187\\n         1.0       0.70      0.79      0.74       118\\n         2.0       0.89      0.42      0.57        19\\n\\n    accuracy                           0.80       324\\n   macro avg       0.82      0.69      0.72       324\\nweighted avg       0.81      0.80      0.80       324\\n']}, 'CNN_LSTM (Validation)': {'Accuracy': [0.6851851851851852, 0.6975308641975309, 0.6975308641975309, 0.7314814814814815, 0.7067901234567902], 'Precision': [0.688473993118802, 0.6991455659789907, 0.6901524081311909, 0.7271944891751656, 0.7107654320987654], 'Recall': [0.6851851851851852, 0.6975308641975309, 0.6975308641975309, 0.7314814814814815, 0.7067901234567902], 'F1_Score': [0.6866551409326599, 0.6909125351100661, 0.6929318965839854, 0.725199588268376, 0.7084212562023605], 'AUC_ROC': [0.8261932617187442, 0.8275644844171166, 0.8238242552974775, 0.8466757108705112, 0.8362200401560753], 'Confusion_Matrix': [array([[144,  42,   2],\n",
      "       [ 38,  70,   9],\n",
      "       [  1,  10,   8]]), array([[145,  42,   1],\n",
      "       [ 39,  77,   1],\n",
      "       [  6,   9,   4]]), array([[153,  34,   1],\n",
      "       [ 44,  66,   7],\n",
      "       [  2,  10,   7]]), array([[156,  30,   2],\n",
      "       [ 41,  75,   1],\n",
      "       [  3,  10,   6]]), array([[144,  40,   3],\n",
      "       [ 33,  77,   8],\n",
      "       [  3,   8,   8]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.79      0.77      0.78       188\\n         1.0       0.57      0.60      0.59       117\\n         2.0       0.42      0.42      0.42        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.59      0.60      0.59       324\\nweighted avg       0.69      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.77      0.77       188\\n         1.0       0.60      0.66      0.63       117\\n         2.0       0.67      0.21      0.32        19\\n\\n    accuracy                           0.70       324\\n   macro avg       0.68      0.55      0.57       324\\nweighted avg       0.70      0.70      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.77      0.81      0.79       188\\n         1.0       0.60      0.56      0.58       117\\n         2.0       0.47      0.37      0.41        19\\n\\n    accuracy                           0.70       324\\n   macro avg       0.61      0.58      0.59       324\\nweighted avg       0.69      0.70      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.83      0.80       188\\n         1.0       0.65      0.64      0.65       117\\n         2.0       0.67      0.32      0.43        19\\n\\n    accuracy                           0.73       324\\n   macro avg       0.70      0.60      0.63       324\\nweighted avg       0.73      0.73      0.73       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.77      0.78       187\\n         1.0       0.62      0.65      0.63       118\\n         2.0       0.42      0.42      0.42        19\\n\\n    accuracy                           0.71       324\\n   macro avg       0.61      0.61      0.61       324\\nweighted avg       0.71      0.71      0.71       324\\n']}, 'SVM (Validation)': {'Accuracy': [0.6574074074074074, 0.7037037037037037, 0.7129629629629629, 0.691358024691358, 0.6481481481481481], 'Precision': [0.6590969961194995, 0.6903574358919636, 0.7108370661713828, 0.6877496303422229, 0.6525559184584999], 'Recall': [0.6574074074074074, 0.7037037037037037, 0.7129629629629629, 0.691358024691358, 0.6481481481481481], 'F1_Score': [0.6563352309936816, 0.6948092031425367, 0.7117820719269994, 0.6885726616080676, 0.6497322821396895], 'AUC_ROC': [0.7862593274552766, 0.8146707189162898, 0.8223172279157198, 0.7973510732267354, 0.7613995311209011], 'Confusion_Matrix': [array([[140,  48,   0],\n",
      "       [ 50,  64,   3],\n",
      "       [  3,   7,   9]]), array([[158,  28,   2],\n",
      "       [ 41,  67,   9],\n",
      "       [  8,   8,   3]]), array([[152,  35,   1],\n",
      "       [ 38,  70,   9],\n",
      "       [  2,   8,   9]]), array([[151,  34,   3],\n",
      "       [ 44,  64,   9],\n",
      "       [  3,   7,   9]]), array([[138,  48,   1],\n",
      "       [ 44,  61,  13],\n",
      "       [  1,   7,  11]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.73      0.74      0.73       188\\n         1.0       0.54      0.55      0.54       117\\n         2.0       0.75      0.47      0.58        19\\n\\n    accuracy                           0.66       324\\n   macro avg       0.67      0.59      0.62       324\\nweighted avg       0.66      0.66      0.66       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.84      0.80       188\\n         1.0       0.65      0.57      0.61       117\\n         2.0       0.21      0.16      0.18        19\\n\\n    accuracy                           0.70       324\\n   macro avg       0.54      0.52      0.53       324\\nweighted avg       0.69      0.70      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.79      0.81      0.80       188\\n         1.0       0.62      0.60      0.61       117\\n         2.0       0.47      0.47      0.47        19\\n\\n    accuracy                           0.71       324\\n   macro avg       0.63      0.63      0.63       324\\nweighted avg       0.71      0.71      0.71       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.80      0.78       188\\n         1.0       0.61      0.55      0.58       117\\n         2.0       0.43      0.47      0.45        19\\n\\n    accuracy                           0.69       324\\n   macro avg       0.60      0.61      0.60       324\\nweighted avg       0.69      0.69      0.69       324\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.75      0.74      0.75       187\\n         1.0       0.53      0.52      0.52       118\\n         2.0       0.44      0.58      0.50        19\\n\\n    accuracy                           0.65       324\\n   macro avg       0.57      0.61      0.59       324\\nweighted avg       0.65      0.65      0.65       324\\n']}, 'LSTM (Test)': {'Accuracy': [0.7019704433497537, 0.7142857142857143, 0.7044334975369458, 0.6650246305418719, 0.6921182266009852], 'Precision': [0.6915708812260536, 0.7096398943768972, 0.6977076927502779, 0.6551309252319196, 0.6912652048490626], 'Recall': [0.7019704433497537, 0.7142857142857143, 0.7044334975369458, 0.6650246305418719, 0.6921182266009852], 'F1_Score': [0.6961498031617784, 0.711052705969451, 0.7002961432197631, 0.6592554333261902, 0.6915868820119003], 'AUC_ROC': [0.8133501316956435, 0.8315094766070554, 0.8377329611924496, 0.7966026241871342, 0.8154201152377447], 'Confusion_Matrix': [array([[189,  41,   5],\n",
      "       [ 48,  92,   7],\n",
      "       [  6,  14,   4]]), array([[189,  45,   1],\n",
      "       [ 48,  92,   7],\n",
      "       [  6,   9,   9]]), array([[190,  43,   2],\n",
      "       [ 51,  88,   8],\n",
      "       [  5,  11,   8]]), array([[184,  47,   4],\n",
      "       [ 57,  81,   9],\n",
      "       [  8,  11,   5]]), array([[187,  42,   6],\n",
      "       [ 48,  87,  12],\n",
      "       [  4,  13,   7]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.80      0.79       235\\n         1.0       0.63      0.63      0.63       147\\n         2.0       0.25      0.17      0.20        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.55      0.53      0.54       406\\nweighted avg       0.69      0.70      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.80      0.79       235\\n         1.0       0.63      0.63      0.63       147\\n         2.0       0.53      0.38      0.44        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.65      0.60      0.62       406\\nweighted avg       0.71      0.71      0.71       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.77      0.81      0.79       235\\n         1.0       0.62      0.60      0.61       147\\n         2.0       0.44      0.33      0.38        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.61      0.58      0.59       406\\nweighted avg       0.70      0.70      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.74      0.78      0.76       235\\n         1.0       0.58      0.55      0.57       147\\n         2.0       0.28      0.21      0.24        24\\n\\n    accuracy                           0.67       406\\n   macro avg       0.53      0.51      0.52       406\\nweighted avg       0.66      0.67      0.66       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.80      0.79       235\\n         1.0       0.61      0.59      0.60       147\\n         2.0       0.28      0.29      0.29        24\\n\\n    accuracy                           0.69       406\\n   macro avg       0.56      0.56      0.56       406\\nweighted avg       0.69      0.69      0.69       406\\n']}, 'Transformer (Test)': {'Accuracy': [0.7068965517241379, 0.7019704433497537, 0.7093596059113301, 0.7118226600985221, 0.7364532019704434], 'Precision': [0.7030142736577393, 0.7209391183529114, 0.7068161174126756, 0.7010430585748191, 0.7239877307310256], 'Recall': [0.7068965517241379, 0.7019704433497537, 0.7093596059113301, 0.7118226600985221, 0.7364532019704434], 'F1_Score': [0.7046054345882645, 0.7018137092601521, 0.7060107919908284, 0.7040928261417602, 0.728823199678776], 'AUC_ROC': [0.8337328312368594, 0.8081839427695945, 0.8317889324877367, 0.8214091859971995, 0.8575081019575764], 'Confusion_Matrix': [array([[191,  37,   7],\n",
      "       [ 43,  92,  12],\n",
      "       [ 10,  10,   4]]), array([[166,  66,   3],\n",
      "       [ 24, 115,   8],\n",
      "       [  5,  15,   4]]), array([[182,  51,   2],\n",
      "       [ 39, 101,   7],\n",
      "       [  6,  13,   5]]), array([[193,  41,   1],\n",
      "       [ 50,  91,   6],\n",
      "       [  4,  15,   5]]), array([[197,  37,   1],\n",
      "       [ 41,  98,   8],\n",
      "       [  5,  15,   4]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.81      0.80       235\\n         1.0       0.66      0.63      0.64       147\\n         2.0       0.17      0.17      0.17        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.54      0.54      0.54       406\\nweighted avg       0.70      0.71      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.71      0.77       235\\n         1.0       0.59      0.78      0.67       147\\n         2.0       0.27      0.17      0.21        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.57      0.55      0.55       406\\nweighted avg       0.72      0.70      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.77      0.79       235\\n         1.0       0.61      0.69      0.65       147\\n         2.0       0.36      0.21      0.26        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.59      0.56      0.57       406\\nweighted avg       0.71      0.71      0.71       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.82      0.80       235\\n         1.0       0.62      0.62      0.62       147\\n         2.0       0.42      0.21      0.28        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.61      0.55      0.57       406\\nweighted avg       0.70      0.71      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.81      0.84      0.82       235\\n         1.0       0.65      0.67      0.66       147\\n         2.0       0.31      0.17      0.22        24\\n\\n    accuracy                           0.74       406\\n   macro avg       0.59      0.56      0.57       406\\nweighted avg       0.72      0.74      0.73       406\\n']}, 'XGBoost (Test)': {'Accuracy': [0.7684729064039408, 0.7783251231527094, 0.7758620689655172, 0.7487684729064039, 0.7610837438423645], 'Precision': [0.7590973184248505, 0.7728545537926351, 0.7749742565160983, 0.7446834450658666, 0.7556192755940443], 'Recall': [0.7684729064039408, 0.7783251231527094, 0.7758620689655172, 0.7487684729064039, 0.7610837438423645], 'F1_Score': [0.7601260853964252, 0.7738385687514792, 0.7668081171453611, 0.7447533607401041, 0.7556199625165143], 'AUC_ROC': [0.8899652577011482, 0.8934911352403448, 0.8910996660488643, 0.8868312593446199, 0.8918301882892001], 'Confusion_Matrix': [array([[206,  28,   1],\n",
      "       [ 43, 100,   4],\n",
      "       [  0,  18,   6]]), array([[204,  29,   2],\n",
      "       [ 40, 103,   4],\n",
      "       [  1,  14,   9]]), array([[203,  32,   0],\n",
      "       [ 38, 107,   2],\n",
      "       [  0,  19,   5]]), array([[196,  37,   2],\n",
      "       [ 43, 100,   4],\n",
      "       [  1,  15,   8]]), array([[201,  33,   1],\n",
      "       [ 43, 100,   4],\n",
      "       [  2,  14,   8]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.88      0.85       235\\n         1.0       0.68      0.68      0.68       147\\n         2.0       0.55      0.25      0.34        24\\n\\n    accuracy                           0.77       406\\n   macro avg       0.69      0.60      0.63       406\\nweighted avg       0.76      0.77      0.76       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.87      0.85       235\\n         1.0       0.71      0.70      0.70       147\\n         2.0       0.60      0.38      0.46        24\\n\\n    accuracy                           0.78       406\\n   macro avg       0.71      0.65      0.67       406\\nweighted avg       0.77      0.78      0.77       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.86      0.85       235\\n         1.0       0.68      0.73      0.70       147\\n         2.0       0.71      0.21      0.32        24\\n\\n    accuracy                           0.78       406\\n   macro avg       0.74      0.60      0.63       406\\nweighted avg       0.77      0.78      0.77       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.83      0.83       235\\n         1.0       0.66      0.68      0.67       147\\n         2.0       0.57      0.33      0.42        24\\n\\n    accuracy                           0.75       406\\n   macro avg       0.68      0.62      0.64       406\\nweighted avg       0.74      0.75      0.74       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.86      0.84       235\\n         1.0       0.68      0.68      0.68       147\\n         2.0       0.62      0.33      0.43        24\\n\\n    accuracy                           0.76       406\\n   macro avg       0.70      0.62      0.65       406\\nweighted avg       0.76      0.76      0.76       406\\n']}, 'DecisionTree (Test)': {'Accuracy': [0.7093596059113301, 0.7068965517241379, 0.6674876847290641, 0.7019704433497537, 0.6551724137931034], 'Precision': [0.7115232299816479, 0.7022184971654115, 0.6563292190180994, 0.7106463021406071, 0.6524090485647362], 'Recall': [0.7093596059113301, 0.7068965517241379, 0.6674876847290641, 0.7019704433497537, 0.6551724137931034], 'F1_Score': [0.7097522246785071, 0.7041267764973697, 0.6571575541177521, 0.7058473406879392, 0.6523952577853328], 'AUC_ROC': [0.7343374650484046, 0.7285552095417073, 0.6832645147607949, 0.7371153580853224, 0.684418081428277], 'Confusion_Matrix': [array([[190,  39,   6],\n",
      "       [ 47,  87,  13],\n",
      "       [  3,  10,  11]]), array([[193,  38,   4],\n",
      "       [ 48,  87,  12],\n",
      "       [  4,  13,   7]]), array([[198,  31,   6],\n",
      "       [ 64,  69,  14],\n",
      "       [  5,  15,   4]]), array([[183,  47,   5],\n",
      "       [ 39,  93,  15],\n",
      "       [  3,  12,   9]]), array([[189,  42,   4],\n",
      "       [ 57,  71,  19],\n",
      "       [  3,  15,   6]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.79      0.81      0.80       235\\n         1.0       0.64      0.59      0.61       147\\n         2.0       0.37      0.46      0.41        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.60      0.62      0.61       406\\nweighted avg       0.71      0.71      0.71       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.79      0.82      0.80       235\\n         1.0       0.63      0.59      0.61       147\\n         2.0       0.30      0.29      0.30        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.57      0.57      0.57       406\\nweighted avg       0.70      0.71      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.74      0.84      0.79       235\\n         1.0       0.60      0.47      0.53       147\\n         2.0       0.17      0.17      0.17        24\\n\\n    accuracy                           0.67       406\\n   macro avg       0.50      0.49      0.49       406\\nweighted avg       0.66      0.67      0.66       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.81      0.78      0.80       235\\n         1.0       0.61      0.63      0.62       147\\n         2.0       0.31      0.38      0.34        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.58      0.60      0.59       406\\nweighted avg       0.71      0.70      0.71       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.80      0.78       235\\n         1.0       0.55      0.48      0.52       147\\n         2.0       0.21      0.25      0.23        24\\n\\n    accuracy                           0.66       406\\n   macro avg       0.51      0.51      0.51       406\\nweighted avg       0.65      0.66      0.65       406\\n']}, 'RandomForest (Test)': {'Accuracy': [0.7783251231527094, 0.7660098522167488, 0.7610837438423645, 0.7610837438423645, 0.7733990147783252], 'Precision': [0.7699876728531999, 0.7616724208216864, 0.7552292875510647, 0.7621217717533766, 0.7701627020971747], 'Recall': [0.7783251231527094, 0.7660098522167488, 0.7610837438423645, 0.7610837438423645, 0.7733990147783252], 'F1_Score': [0.7692141693163936, 0.7579437925422652, 0.7511592073162032, 0.7538683349927994, 0.765898928867988], 'AUC_ROC': [0.8837562746285175, 0.8956835015106709, 0.8900038377755848, 0.8961904660781863, 0.8928227934642803], 'Confusion_Matrix': [array([[205,  29,   1],\n",
      "       [ 38, 106,   3],\n",
      "       [  1,  18,   5]]), array([[202,  32,   1],\n",
      "       [ 42, 103,   2],\n",
      "       [  2,  16,   6]]), array([[200,  34,   1],\n",
      "       [ 40, 105,   2],\n",
      "       [  0,  20,   4]]), array([[199,  36,   0],\n",
      "       [ 41, 104,   2],\n",
      "       [  1,  17,   6]]), array([[202,  32,   1],\n",
      "       [ 39, 106,   2],\n",
      "       [  1,  17,   6]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.87      0.86       235\\n         1.0       0.69      0.72      0.71       147\\n         2.0       0.56      0.21      0.30        24\\n\\n    accuracy                           0.78       406\\n   macro avg       0.70      0.60      0.62       406\\nweighted avg       0.77      0.78      0.77       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.86      0.84       235\\n         1.0       0.68      0.70      0.69       147\\n         2.0       0.67      0.25      0.36        24\\n\\n    accuracy                           0.77       406\\n   macro avg       0.72      0.60      0.63       406\\nweighted avg       0.76      0.77      0.76       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.85      0.84       235\\n         1.0       0.66      0.71      0.69       147\\n         2.0       0.57      0.17      0.26        24\\n\\n    accuracy                           0.76       406\\n   macro avg       0.69      0.58      0.60       406\\nweighted avg       0.76      0.76      0.75       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.85      0.84       235\\n         1.0       0.66      0.71      0.68       147\\n         2.0       0.75      0.25      0.38        24\\n\\n    accuracy                           0.76       406\\n   macro avg       0.75      0.60      0.63       406\\nweighted avg       0.76      0.76      0.75       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.83      0.86      0.85       235\\n         1.0       0.68      0.72      0.70       147\\n         2.0       0.67      0.25      0.36        24\\n\\n    accuracy                           0.77       406\\n   macro avg       0.73      0.61      0.64       406\\nweighted avg       0.77      0.77      0.77       406\\n']}, 'CNN_LSTM (Test)': {'Accuracy': [0.7068965517241379, 0.6699507389162561, 0.7044334975369458, 0.7093596059113301, 0.6970443349753694], 'Precision': [0.701991861212251, 0.667785871933348, 0.6957710894282273, 0.6959922615490608, 0.6947261663286004], 'Recall': [0.7068965517241379, 0.6699507389162561, 0.7044334975369458, 0.7093596059113301, 0.6970443349753694], 'F1_Score': [0.70323641875366, 0.6636744385660431, 0.698417333189233, 0.701280374218653, 0.6953272343420126], 'AUC_ROC': [0.8329159544672375, 0.7911741963326965, 0.8326792147855231, 0.8351005641483142, 0.8288649007030763], 'Confusion_Matrix': [array([[186,  47,   2],\n",
      "       [ 41,  97,   9],\n",
      "       [  3,  17,   4]]), array([[174,  61,   0],\n",
      "       [ 47,  95,   5],\n",
      "       [  5,  16,   3]]), array([[187,  47,   1],\n",
      "       [ 46,  94,   7],\n",
      "       [  8,  11,   5]]), array([[192,  42,   1],\n",
      "       [ 46,  93,   8],\n",
      "       [  3,  18,   3]]), array([[183,  49,   3],\n",
      "       [ 48,  92,   7],\n",
      "       [  4,  12,   8]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.81      0.79      0.80       235\\n         1.0       0.60      0.66      0.63       147\\n         2.0       0.27      0.17      0.21        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.56      0.54      0.54       406\\nweighted avg       0.70      0.71      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.77      0.74      0.75       235\\n         1.0       0.55      0.65      0.60       147\\n         2.0       0.38      0.12      0.19        24\\n\\n    accuracy                           0.67       406\\n   macro avg       0.57      0.50      0.51       406\\nweighted avg       0.67      0.67      0.66       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.80      0.79       235\\n         1.0       0.62      0.64      0.63       147\\n         2.0       0.38      0.21      0.27        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.59      0.55      0.56       406\\nweighted avg       0.70      0.70      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.80      0.82      0.81       235\\n         1.0       0.61      0.63      0.62       147\\n         2.0       0.25      0.12      0.17        24\\n\\n    accuracy                           0.71       406\\n   macro avg       0.55      0.52      0.53       406\\nweighted avg       0.70      0.71      0.70       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.78      0.78      0.78       235\\n         1.0       0.60      0.63      0.61       147\\n         2.0       0.44      0.33      0.38        24\\n\\n    accuracy                           0.70       406\\n   macro avg       0.61      0.58      0.59       406\\nweighted avg       0.69      0.70      0.70       406\\n']}, 'SVM (Test)': {'Accuracy': [0.33004926108374383, 0.3078817733990148, 0.3374384236453202, 0.28078817733990147, 0.33497536945812806], 'Precision': [0.1364496042508441, 0.13656577150969773, 0.4925209020474947, 0.13890764408005787, 0.5498559709258257], 'Recall': [0.33004926108374383, 0.3078817733990148, 0.3374384236453202, 0.28078817733990147, 0.33497536945812806], 'F1_Score': [0.19306951527421812, 0.18911005849933007, 0.2761573293951968, 0.18469114172705794, 0.21567208131471458], 'AUC_ROC': [0.5342668535170915, 0.5207742447533568, 0.5566650885583825, 0.527674550821593, 0.5270296015408933], 'Confusion_Matrix': [array([[  0, 200,  35],\n",
      "       [  0, 133,  14],\n",
      "       [  0,  23,   1]]), array([[  0, 186,  49],\n",
      "       [  0, 122,  25],\n",
      "       [  0,  21,   3]]), array([[ 20, 163,  52],\n",
      "       [ 12, 113,  22],\n",
      "       [  1,  19,   4]]), array([[  0, 162,  73],\n",
      "       [  0, 107,  40],\n",
      "       [  0,  17,   7]]), array([[  5, 195,  35],\n",
      "       [  2, 130,  15],\n",
      "       [  0,  23,   1]])], 'Classification_Report': ['              precision    recall  f1-score   support\\n\\n         0.0       0.00      0.00      0.00       235\\n         1.0       0.37      0.90      0.53       147\\n         2.0       0.02      0.04      0.03        24\\n\\n    accuracy                           0.33       406\\n   macro avg       0.13      0.32      0.19       406\\nweighted avg       0.14      0.33      0.19       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.00      0.00      0.00       235\\n         1.0       0.37      0.83      0.51       147\\n         2.0       0.04      0.12      0.06        24\\n\\n    accuracy                           0.31       406\\n   macro avg       0.14      0.32      0.19       406\\nweighted avg       0.14      0.31      0.19       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.61      0.09      0.15       235\\n         1.0       0.38      0.77      0.51       147\\n         2.0       0.05      0.17      0.08        24\\n\\n    accuracy                           0.34       406\\n   macro avg       0.35      0.34      0.25       406\\nweighted avg       0.49      0.34      0.28       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.00      0.00      0.00       235\\n         1.0       0.37      0.73      0.49       147\\n         2.0       0.06      0.29      0.10        24\\n\\n    accuracy                           0.28       406\\n   macro avg       0.14      0.34      0.20       406\\nweighted avg       0.14      0.28      0.18       406\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.71      0.02      0.04       235\\n         1.0       0.37      0.88      0.53       147\\n         2.0       0.02      0.04      0.03        24\\n\\n    accuracy                           0.33       406\\n   macro avg       0.37      0.32      0.20       406\\nweighted avg       0.55      0.33      0.22       406\\n']}}\n",
      "------------------------------------------------------------------\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "interval_split = 12\n",
    "# Get the current timestamp\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Set up logging with timestamp in filename\n",
    "log_filename = f'/home/rxb2495/logs/model_processing_3_6_12_24_hour_interval_{current_time}.log'\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# Custom callback for logging per epoch\n",
    "class EpochLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logging.info(f\"Epoch {epoch + 1} - loss: {logs['loss']:.4f}, accuracy: {logs['accuracy']:.4f}, \"\n",
    "                     f\"val_loss: {logs['val_loss']:.4f}, val_accuracy: {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Function to split data into intervals\n",
    "def split_into_intervals(data, interval_size, stride):\n",
    "    logging.info(\"Splitting data into intervals.\")\n",
    "    intervals = []\n",
    "    num_intervals = (data.shape[0] - interval_size) // stride + 1\n",
    "    for i in range(num_intervals):\n",
    "        start_ix = i * stride\n",
    "        end_ix = start_ix + interval_size\n",
    "        interval = data[start_ix:end_ix]\n",
    "        intervals.append(interval)\n",
    "    return np.array(intervals)\n",
    "\n",
    "# Function to capture and log metrics\n",
    "def capture_metrics(y_test, y_pred, y_pred_probs, model_name, model_results):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Confusion Matrix and Classification Report\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # AUC-ROC Calculation\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_probs, multi_class='ovr', average='weighted')\n",
    "    except ValueError:\n",
    "        auc_roc = 'N/A'\n",
    "\n",
    "    # Append metrics to the results dictionary\n",
    "    model_results[model_name]['Accuracy'].append(accuracy)\n",
    "    model_results[model_name]['Precision'].append(precision)\n",
    "    model_results[model_name]['Recall'].append(recall)\n",
    "    model_results[model_name]['F1_Score'].append(f1)\n",
    "    model_results[model_name]['AUC_ROC'].append(auc_roc)\n",
    "    model_results[model_name]['Confusion_Matrix'].append(conf_matrix)\n",
    "    model_results[model_name]['Classification_Report'].append(class_report)\n",
    "\n",
    "    # Log the metrics\n",
    "    logging.info(f\"{model_name} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}, AUC-ROC: {auc_roc}\")\n",
    "    return model_results\n",
    "\n",
    "# Loop through each ID and perform the data processing and model evaluation\n",
    "for id_ in ids[:1]:\n",
    "    logging.info(f\"Processing ID: {id_}\")\n",
    "    \n",
    "    # Load the combined data tuple from the .npy file for the current ID\n",
    "    file_path = f'/home/rxb2495/data/{id_}_all_data.npy'\n",
    "    loaded_data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "    # Reconstruct DataFrames from the loaded data\n",
    "    intervals = pd.DataFrame(data=loaded_data[0][1], columns=loaded_data[0][0])\n",
    "    output_data = pd.DataFrame(data=loaded_data[1][1], columns=loaded_data[1][0])\n",
    "\n",
    "    # Handle missing values\n",
    "    if output_data.isnull().values.any():\n",
    "        logging.warning(f\"The output_data DataFrame for {id_} contains NaN values.\")\n",
    "    if intervals.isnull().values.any():\n",
    "        logging.warning(f\"The intervals DataFrame for {id_} contains NaN values.\")\n",
    "\n",
    "    intervals = intervals[features]\n",
    "    \n",
    "    # Prepare output data for classification\n",
    "    output_data = output_data[[\"Historic Glucose mg/dL\"]]\n",
    "    \n",
    "    # Reduce memory usage by converting to appropriate data types\n",
    "    intervals = intervals.astype(np.float32)\n",
    "    output_data = output_data.astype(np.float32)\n",
    "\n",
    "    # Create categorical bins for binary classification\n",
    "    bins = [0, 100, float('inf')]  # 0-100 is one class, >100 is the second class\n",
    "    labels = [0, 1]  # Class 0: 0-100, Class 1: >100\n",
    "\n",
    "    # Create the new 'Glucose_Category' based on the specified bins\n",
    "    output_data['Glucose_Category'] = pd.cut(output_data['Historic Glucose mg/dL'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Encode the categories using LabelEncoder (though not strictly necessary since labels are already 0 and 1)\n",
    "    label_encoder = LabelEncoder()\n",
    "    output_data['Glucose_Label'] = label_encoder.fit_transform(output_data['Glucose_Category'])\n",
    "\n",
    "    glucose_label_counts = output_data['Glucose_Label'].value_counts()\n",
    "\n",
    "    # Convert value counts to dictionary\n",
    "    glucose_label_counts_dict = glucose_label_counts.to_dict()\n",
    "\n",
    "    # Log the value counts as a dictionary\n",
    "    logging.info(\"Glucose_Label value counts (as dictionary):\")\n",
    "    logging.info(f\"{glucose_label_counts_dict}\")\n",
    "\n",
    "    # Perform classification\n",
    "    output_data_scaled = output_data[[\"Glucose_Label\"]].values.astype(np.float32)\n",
    "\n",
    "    logging.info(f\"Total size of data: {output_data_scaled.shape[0]}\")\n",
    "\n",
    "    # Split data into intervals\n",
    "    interval_size = 96\n",
    "    intervals = split_into_intervals(intervals, interval_size, interval_size)\n",
    "\n",
    "    last_12 = intervals[:, -interval_split:, :]  # Last 24 entries\n",
    "\n",
    "    intervals = last_12.astype(np.float32)\n",
    "    output_data_scaled = output_data_scaled.astype(np.float32)\n",
    "\n",
    "    feature_size = intervals.shape[2]\n",
    "    num_classes = 2\n",
    "\n",
    "    # Train-Test Split: Keep test set aside (20%)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(intervals, output_data_scaled, test_size=0.2, stratify=output_data_scaled, random_state=42)\n",
    "\n",
    "    # Initialize stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    # Dictionary to store metrics for each model and ID\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    # Initialize stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # List to store the models for evaluation\n",
    "    model_names = ['LSTM', 'Transformer', 'XGBoost', 'DecisionTree', 'RandomForest', 'CNN_LSTM']\n",
    "\n",
    "    # Modified model names with Validation and Test tags\n",
    "    model_names_with_tags = [f\"{name} (Validation)\" for name in model_names] + [f\"{name} (Test)\" for name in model_names]\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    ############################ LSTM Model ############################\n",
    "    logging.info(f\"Starting LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(128, input_shape=(interval_split, feature_size), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        lstm_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "        logging.info(f\"LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ Transformer Model ############################\n",
    "    logging.info(f\"Starting Transformer model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define Transformer model\n",
    "        transformer_model = TransformerModel(\n",
    "            input_dim=128,          # Example input dimension (sequence length or feature size)\n",
    "            head_size=64,           # Size of each attention head\n",
    "            num_heads=4,            # Number of attention heads\n",
    "            ff_dim=256,             # Hidden layer size in the feed-forward network\n",
    "            num_transformer_blocks=3, # Number of transformer blocks\n",
    "            mlp_units=[128, 64],    # Units in the multi-layer perceptron (MLP)\n",
    "            num_classes=2,          # Number of output classes (for classification)\n",
    "            dropout=0.1,            # Dropout rate in transformer and feed-forward layers\n",
    "            mlp_dropout=0.1         # Dropout rate in the MLP layers\n",
    "        )\n",
    "\n",
    "        transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        transformer_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = transformer_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'Transformer (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = transformer_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'Transformer (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del transformer_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Transformer model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    # Flatten the input data for compatibility with the models\n",
    "    X_full_flattened = intervals.reshape(intervals.shape[0], -1)\n",
    "    y_full = output_data_scaled.flatten()\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    logging.info(f\"Starting XGBoost model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the XGBoost model\n",
    "        xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = xgb_model.predict(X_val)\n",
    "        y_val_pred_probs = xgb_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'XGBoost (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del xgb_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"XGBoost model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Decision Tree Model ############################\n",
    "    logging.info(f\"Starting Decision Tree model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Decision Tree model\n",
    "        dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = dt_model.predict(X_val)\n",
    "        y_val_pred_probs = dt_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'DecisionTree (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del dt_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Decision Tree model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Random Forest Model ############################\n",
    "    logging.info(f\"Starting Random Forest model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "        y_val_pred_probs = rf_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'RandomForest (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del rf_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Random Forest model training and testing complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ CNN-LSTM Model ############################\n",
    "    logging.info(f\"Starting CNN-LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define CNN-LSTM model\n",
    "        cnn_lstm_model = Sequential([\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(interval_split, feature_size)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        cnn_lstm_model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = cnn_lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'CNN_LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = cnn_lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'CNN_LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cnn_lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"CNN-LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ SVM Model ############################\n",
    "\n",
    "    # Logging the results at the end of each ID processing\n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    logging.info(f\"Processing completed for ID: {id_}\")\n",
    "    \n",
    "    # Manually format and log model results with mean and std deviation\n",
    "    for model_name, metrics in model_results.items():\n",
    "        logging.info(f\"Model: {model_name}\")\n",
    "        \n",
    "        # Log each metric with comma-separated values and compute mean and std\n",
    "        for metric_name in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
    "            metric_values = metrics[metric_name]\n",
    "            \n",
    "            # Skip calculations for 'AUC_ROC' if it contains invalid data\n",
    "            if metric_name == 'AUC_ROC' and (not metric_values or any(val is None for val in metric_values)):\n",
    "                logging.info(f\"AUC_ROC: Not available due to null values\")\n",
    "                continue\n",
    "            \n",
    "            # Compute mean and std only for valid data\n",
    "            mean_value = np.mean(metric_values) if metric_values else 0\n",
    "            std_value = np.std(metric_values) if metric_values else 0\n",
    "            \n",
    "            # Log the metric values, mean, and std deviation\n",
    "            logging.info(f\"{metric_name}: {', '.join(map(str, metric_values))}\")\n",
    "            logging.info(f\"{metric_name} (Mean): {mean_value:.4f}\")\n",
    "            logging.info(f\"{metric_name} (Std): {std_value:.4f}\")\n",
    "        \n",
    "        # Confusion Matrix and Classification Report can be tricky to format, but here's one way to handle them:\n",
    "        for i, conf_matrix in enumerate(metrics['Confusion_Matrix']):\n",
    "            logging.info(f\"Confusion Matrix {i+1}: {conf_matrix}\")\n",
    "        for i, class_report in enumerate(metrics['Classification_Report']):\n",
    "            logging.info(f\"Classification Report {i+1}: {class_report}\")\n",
    "    \n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    # Store results for the current ID\n",
    "    results[f\"id_{interval_split}\"] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_split = 24\n",
    "\n",
    "logging.info(\"Started experiment for 6 hrs interval\")\n",
    "\n",
    "\n",
    "# Loop through each ID and perform the data processing and model evaluation\n",
    "for id_ in ids[:1]:\n",
    "    logging.info(f\"Processing ID: {id_}\")\n",
    "    \n",
    "    # Load the combined data tuple from the .npy file for the current ID\n",
    "    file_path = f'/home/rxb2495/data/{id_}_all_data.npy'\n",
    "    loaded_data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "    # Reconstruct DataFrames from the loaded data\n",
    "    intervals = pd.DataFrame(data=loaded_data[0][1], columns=loaded_data[0][0])\n",
    "    output_data = pd.DataFrame(data=loaded_data[1][1], columns=loaded_data[1][0])\n",
    "\n",
    "    # Handle missing values\n",
    "    if output_data.isnull().values.any():\n",
    "        logging.warning(f\"The output_data DataFrame for {id_} contains NaN values.\")\n",
    "    if intervals.isnull().values.any():\n",
    "        logging.warning(f\"The intervals DataFrame for {id_} contains NaN values.\")\n",
    "\n",
    "    intervals = intervals[features]\n",
    "    \n",
    "    # Prepare output data for classification\n",
    "    output_data = output_data[[\"Historic Glucose mg/dL\"]]\n",
    "    \n",
    "    # Reduce memory usage by converting to appropriate data types\n",
    "    intervals = intervals.astype(np.float32)\n",
    "    output_data = output_data.astype(np.float32)\n",
    "\n",
    "    # Create categorical bins for binary classification\n",
    "    bins = [0, 100, float('inf')]  # 0-100 is one class, >100 is the second class\n",
    "    labels = [0, 1]  # Class 0: 0-100, Class 1: >100\n",
    "\n",
    "    # Create the new 'Glucose_Category' based on the specified bins\n",
    "    output_data['Glucose_Category'] = pd.cut(output_data['Historic Glucose mg/dL'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Encode the categories using LabelEncoder (though not strictly necessary since labels are already 0 and 1)\n",
    "    label_encoder = LabelEncoder()\n",
    "    output_data['Glucose_Label'] = label_encoder.fit_transform(output_data['Glucose_Category'])\n",
    "\n",
    "    glucose_label_counts = output_data['Glucose_Label'].value_counts()\n",
    "\n",
    "    # Convert value counts to dictionary\n",
    "    glucose_label_counts_dict = glucose_label_counts.to_dict()\n",
    "\n",
    "    # Log the value counts as a dictionary\n",
    "    logging.info(\"Glucose_Label value counts (as dictionary):\")\n",
    "    logging.info(f\"{glucose_label_counts_dict}\")\n",
    "\n",
    "    # Perform classification\n",
    "    output_data_scaled = output_data[[\"Glucose_Label\"]].values.astype(np.float32)\n",
    "\n",
    "    logging.info(f\"Total size of data: {output_data_scaled.shape[0]}\")\n",
    "\n",
    "    # Split data into intervals\n",
    "    interval_size = 96\n",
    "    intervals = split_into_intervals(intervals, interval_size, interval_size)\n",
    "\n",
    "    last_24 = intervals[:, -interval_split:, :]  # Last 24 entries\n",
    "\n",
    "    intervals = last_24.astype(np.float32)\n",
    "    output_data_scaled = output_data_scaled.astype(np.float32)\n",
    "\n",
    "    feature_size = intervals.shape[2]\n",
    "    num_classes = 2\n",
    "\n",
    "    # Train-Test Split: Keep test set aside (20%)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(intervals, output_data_scaled, test_size=0.2, stratify=output_data_scaled, random_state=42)\n",
    "\n",
    "    # Initialize stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    # Dictionary to store metrics for each model and ID\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    # Initialize stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # List to store the models for evaluation\n",
    "    model_names = ['LSTM', 'Transformer', 'XGBoost', 'DecisionTree', 'RandomForest', 'CNN_LSTM']\n",
    "\n",
    "    # Modified model names with Validation and Test tags\n",
    "    model_names_with_tags = [f\"{name} (Validation)\" for name in model_names] + [f\"{name} (Test)\" for name in model_names]\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    ############################ LSTM Model ############################\n",
    "    logging.info(f\"Starting LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(128, input_shape=(interval_split, feature_size), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        lstm_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "        logging.info(f\"LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ Transformer Model ############################\n",
    "    logging.info(f\"Starting Transformer model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define Transformer model\n",
    "        transformer_model = TransformerModel(\n",
    "            input_dim=128,          # Example input dimension (sequence length or feature size)\n",
    "            head_size=64,           # Size of each attention head\n",
    "            num_heads=4,            # Number of attention heads\n",
    "            ff_dim=256,             # Hidden layer size in the feed-forward network\n",
    "            num_transformer_blocks=3, # Number of transformer blocks\n",
    "            mlp_units=[128, 64],    # Units in the multi-layer perceptron (MLP)\n",
    "            num_classes=2,          # Number of output classes (for classification)\n",
    "            dropout=0.1,            # Dropout rate in transformer and feed-forward layers\n",
    "            mlp_dropout=0.1         # Dropout rate in the MLP layers\n",
    "        )\n",
    "\n",
    "        transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        transformer_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = transformer_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'Transformer (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = transformer_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'Transformer (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del transformer_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Transformer model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    # Flatten the input data for compatibility with the models\n",
    "    X_full_flattened = intervals.reshape(intervals.shape[0], -1)\n",
    "    y_full = output_data_scaled.flatten()\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    logging.info(f\"Starting XGBoost model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the XGBoost model\n",
    "        xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = xgb_model.predict(X_val)\n",
    "        y_val_pred_probs = xgb_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'XGBoost (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del xgb_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"XGBoost model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Decision Tree Model ############################\n",
    "    logging.info(f\"Starting Decision Tree model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Decision Tree model\n",
    "        dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = dt_model.predict(X_val)\n",
    "        y_val_pred_probs = dt_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'DecisionTree (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del dt_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Decision Tree model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Random Forest Model ############################\n",
    "    logging.info(f\"Starting Random Forest model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "        y_val_pred_probs = rf_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'RandomForest (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del rf_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Random Forest model training and testing complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ CNN-LSTM Model ############################\n",
    "    logging.info(f\"Starting CNN-LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define CNN-LSTM model\n",
    "        cnn_lstm_model = Sequential([\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(interval_split, feature_size)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        cnn_lstm_model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = cnn_lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'CNN_LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = cnn_lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'CNN_LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cnn_lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"CNN-LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ SVM Model ############################\n",
    "\n",
    "    # Logging the results at the end of each ID processing\n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    logging.info(f\"Processing completed for ID: {id_}\")\n",
    "    \n",
    "    # Manually format and log model results with mean and std deviation\n",
    "    for model_name, metrics in model_results.items():\n",
    "        logging.info(f\"Model: {model_name}\")\n",
    "        \n",
    "        # Log each metric with comma-separated values and compute mean and std\n",
    "        for metric_name in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
    "            metric_values = metrics[metric_name]\n",
    "            \n",
    "            # Skip calculations for 'AUC_ROC' if it contains invalid data\n",
    "            if metric_name == 'AUC_ROC' and (not metric_values or any(val is None for val in metric_values)):\n",
    "                logging.info(f\"AUC_ROC: Not available due to null values\")\n",
    "                continue\n",
    "            \n",
    "            # Compute mean and std only for valid data\n",
    "            mean_value = np.mean(metric_values) if metric_values else 0\n",
    "            std_value = np.std(metric_values) if metric_values else 0\n",
    "            \n",
    "            # Log the metric values, mean, and std deviation\n",
    "            logging.info(f\"{metric_name}: {', '.join(map(str, metric_values))}\")\n",
    "            logging.info(f\"{metric_name} (Mean): {mean_value:.4f}\")\n",
    "            logging.info(f\"{metric_name} (Std): {std_value:.4f}\")\n",
    "        \n",
    "        # Confusion Matrix and Classification Report can be tricky to format, but here's one way to handle them:\n",
    "        for i, conf_matrix in enumerate(metrics['Confusion_Matrix']):\n",
    "            logging.info(f\"Confusion Matrix {i+1}: {conf_matrix}\")\n",
    "        for i, class_report in enumerate(metrics['Classification_Report']):\n",
    "            logging.info(f\"Classification Report {i+1}: {class_report}\")\n",
    "    \n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    # Store results for the current ID\n",
    "    results[f\"id_{interval_split}\"] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_split = 48\n",
    "\n",
    "logging.info(\"Started experiment for 12 hrs interval\")\n",
    "\n",
    "# Loop through each ID and perform the data processing and model evaluation\n",
    "for id_ in ids[:1]:\n",
    "    logging.info(f\"Processing ID: {id_}\")\n",
    "    \n",
    "    # Load the combined data tuple from the .npy file for the current ID\n",
    "    file_path = f'/home/rxb2495/data/{id_}_all_data.npy'\n",
    "    loaded_data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "    # Reconstruct DataFrames from the loaded data\n",
    "    intervals = pd.DataFrame(data=loaded_data[0][1], columns=loaded_data[0][0])\n",
    "    output_data = pd.DataFrame(data=loaded_data[1][1], columns=loaded_data[1][0])\n",
    "\n",
    "    # Handle missing values\n",
    "    if output_data.isnull().values.any():\n",
    "        logging.warning(f\"The output_data DataFrame for {id_} contains NaN values.\")\n",
    "    if intervals.isnull().values.any():\n",
    "        logging.warning(f\"The intervals DataFrame for {id_} contains NaN values.\")\n",
    "\n",
    "    intervals = intervals[features]\n",
    "    \n",
    "    # Prepare output data for classification\n",
    "    output_data = output_data[[\"Historic Glucose mg/dL\"]]\n",
    "    \n",
    "    # Reduce memory usage by converting to appropriate data types\n",
    "    intervals = intervals.astype(np.float32)\n",
    "    output_data = output_data.astype(np.float32)\n",
    "\n",
    "    # Create categorical bins for binary classification\n",
    "    bins = [0, 100, float('inf')]  # 0-100 is one class, >100 is the second class\n",
    "    labels = [0, 1]  # Class 0: 0-100, Class 1: >100\n",
    "\n",
    "    # Create the new 'Glucose_Category' based on the specified bins\n",
    "    output_data['Glucose_Category'] = pd.cut(output_data['Historic Glucose mg/dL'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Encode the categories using LabelEncoder (though not strictly necessary since labels are already 0 and 1)\n",
    "    label_encoder = LabelEncoder()\n",
    "    output_data['Glucose_Label'] = label_encoder.fit_transform(output_data['Glucose_Category'])\n",
    "\n",
    "    glucose_label_counts = output_data['Glucose_Label'].value_counts()\n",
    "\n",
    "    # Convert value counts to dictionary\n",
    "    glucose_label_counts_dict = glucose_label_counts.to_dict()\n",
    "\n",
    "    # Log the value counts as a dictionary\n",
    "    logging.info(\"Glucose_Label value counts (as dictionary):\")\n",
    "    logging.info(f\"{glucose_label_counts_dict}\")\n",
    "\n",
    "    # Perform classification\n",
    "    output_data_scaled = output_data[[\"Glucose_Label\"]].values.astype(np.float32)\n",
    "\n",
    "    logging.info(f\"Total size of data: {output_data_scaled.shape[0]}\")\n",
    "\n",
    "    # Split data into intervals\n",
    "    interval_size = 96\n",
    "    intervals = split_into_intervals(intervals, interval_size, interval_size)\n",
    "\n",
    "    last_48 = intervals[:, -interval_split:, :]  # Last 24 entries\n",
    "\n",
    "    intervals = last_48.astype(np.float32)\n",
    "    output_data_scaled = output_data_scaled.astype(np.float32)\n",
    "\n",
    "    feature_size = intervals.shape[2]\n",
    "    num_classes = 2\n",
    "\n",
    "    # Train-Test Split: Keep test set aside (20%)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(intervals, output_data_scaled, test_size=0.2, stratify=output_data_scaled, random_state=42)\n",
    "\n",
    "    # Initialize stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    # Dictionary to store metrics for each model and ID\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    # Initialize stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # List to store the models for evaluation\n",
    "    model_names = ['LSTM', 'Transformer', 'XGBoost', 'DecisionTree', 'RandomForest', 'CNN_LSTM']\n",
    "\n",
    "    # Modified model names with Validation and Test tags\n",
    "    model_names_with_tags = [f\"{name} (Validation)\" for name in model_names] + [f\"{name} (Test)\" for name in model_names]\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    ############################ LSTM Model ############################\n",
    "    logging.info(f\"Starting LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(128, input_shape=(interval_split, feature_size), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        lstm_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "        logging.info(f\"LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ Transformer Model ############################\n",
    "    logging.info(f\"Starting Transformer model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define Transformer model\n",
    "        transformer_model = TransformerModel(\n",
    "            input_dim=128,          # Example input dimension (sequence length or feature size)\n",
    "            head_size=64,           # Size of each attention head\n",
    "            num_heads=4,            # Number of attention heads\n",
    "            ff_dim=256,             # Hidden layer size in the feed-forward network\n",
    "            num_transformer_blocks=3, # Number of transformer blocks\n",
    "            mlp_units=[128, 64],    # Units in the multi-layer perceptron (MLP)\n",
    "            num_classes=2,          # Number of output classes (for classification)\n",
    "            dropout=0.1,            # Dropout rate in transformer and feed-forward layers\n",
    "            mlp_dropout=0.1         # Dropout rate in the MLP layers\n",
    "        )\n",
    "\n",
    "        transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        transformer_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = transformer_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'Transformer (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = transformer_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'Transformer (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del transformer_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Transformer model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    # Flatten the input data for compatibility with the models\n",
    "    X_full_flattened = intervals.reshape(intervals.shape[0], -1)\n",
    "    y_full = output_data_scaled.flatten()\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    logging.info(f\"Starting XGBoost model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the XGBoost model\n",
    "        xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = xgb_model.predict(X_val)\n",
    "        y_val_pred_probs = xgb_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'XGBoost (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del xgb_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"XGBoost model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Decision Tree Model ############################\n",
    "    logging.info(f\"Starting Decision Tree model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Decision Tree model\n",
    "        dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = dt_model.predict(X_val)\n",
    "        y_val_pred_probs = dt_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'DecisionTree (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del dt_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Decision Tree model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Random Forest Model ############################\n",
    "    logging.info(f\"Starting Random Forest model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "        y_val_pred_probs = rf_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'RandomForest (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del rf_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Random Forest model training and testing complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ CNN-LSTM Model ############################\n",
    "    logging.info(f\"Starting CNN-LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define CNN-LSTM model\n",
    "        cnn_lstm_model = Sequential([\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(interval_split, feature_size)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        cnn_lstm_model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = cnn_lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'CNN_LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = cnn_lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'CNN_LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cnn_lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"CNN-LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "\n",
    "    # Logging the results at the end of each ID processing\n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    logging.info(f\"Processing completed for ID: {id_}\")\n",
    "    \n",
    "    # Manually format and log model results with mean and std deviation\n",
    "    for model_name, metrics in model_results.items():\n",
    "        logging.info(f\"Model: {model_name}\")\n",
    "        \n",
    "        # Log each metric with comma-separated values and compute mean and std\n",
    "        for metric_name in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
    "            metric_values = metrics[metric_name]\n",
    "            \n",
    "            # Skip calculations for 'AUC_ROC' if it contains invalid data\n",
    "            if metric_name == 'AUC_ROC' and (not metric_values or any(val is None for val in metric_values)):\n",
    "                logging.info(f\"AUC_ROC: Not available due to null values\")\n",
    "                continue\n",
    "            \n",
    "            # Compute mean and std only for valid data\n",
    "            mean_value = np.mean(metric_values) if metric_values else 0\n",
    "            std_value = np.std(metric_values) if metric_values else 0\n",
    "            \n",
    "            # Log the metric values, mean, and std deviation\n",
    "            logging.info(f\"{metric_name}: {', '.join(map(str, metric_values))}\")\n",
    "            logging.info(f\"{metric_name} (Mean): {mean_value:.4f}\")\n",
    "            logging.info(f\"{metric_name} (Std): {std_value:.4f}\")\n",
    "        \n",
    "        # Confusion Matrix and Classification Report can be tricky to format, but here's one way to handle them:\n",
    "        for i, conf_matrix in enumerate(metrics['Confusion_Matrix']):\n",
    "            logging.info(f\"Confusion Matrix {i+1}: {conf_matrix}\")\n",
    "        for i, class_report in enumerate(metrics['Classification_Report']):\n",
    "            logging.info(f\"Classification Report {i+1}: {class_report}\")\n",
    "    \n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    # Store results for the current ID\n",
    "    results[f\"id_{interval_split}\"] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_split = 96\n",
    "\n",
    "logging.info(\"Started experiment for 12 hrs interval\")\n",
    "\n",
    "# Loop through each ID and perform the data processing and model evaluation\n",
    "for id_ in ids[:1]:\n",
    "    logging.info(f\"Processing ID: {id_}\")\n",
    "    \n",
    "    # Load the combined data tuple from the .npy file for the current ID\n",
    "    file_path = f'/home/rxb2495/data/{id_}_all_data.npy'\n",
    "    loaded_data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "    # Reconstruct DataFrames from the loaded data\n",
    "    intervals = pd.DataFrame(data=loaded_data[0][1], columns=loaded_data[0][0])\n",
    "    output_data = pd.DataFrame(data=loaded_data[1][1], columns=loaded_data[1][0])\n",
    "\n",
    "    # Handle missing values\n",
    "    if output_data.isnull().values.any():\n",
    "        logging.warning(f\"The output_data DataFrame for {id_} contains NaN values.\")\n",
    "    if intervals.isnull().values.any():\n",
    "        logging.warning(f\"The intervals DataFrame for {id_} contains NaN values.\")\n",
    "\n",
    "    intervals = intervals[features]\n",
    "    \n",
    "    # Prepare output data for classification\n",
    "    output_data = output_data[[\"Historic Glucose mg/dL\"]]\n",
    "    \n",
    "    # Reduce memory usage by converting to appropriate data types\n",
    "    intervals = intervals.astype(np.float32)\n",
    "    output_data = output_data.astype(np.float32)\n",
    "\n",
    "    # Create categorical bins for binary classification\n",
    "    bins = [0, 100, float('inf')]  # 0-100 is one class, >100 is the second class\n",
    "    labels = [0, 1]  # Class 0: 0-100, Class 1: >100\n",
    "\n",
    "    # Create the new 'Glucose_Category' based on the specified bins\n",
    "    output_data['Glucose_Category'] = pd.cut(output_data['Historic Glucose mg/dL'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Encode the categories using LabelEncoder (though not strictly necessary since labels are already 0 and 1)\n",
    "    label_encoder = LabelEncoder()\n",
    "    output_data['Glucose_Label'] = label_encoder.fit_transform(output_data['Glucose_Category'])\n",
    "\n",
    "    glucose_label_counts = output_data['Glucose_Label'].value_counts()\n",
    "\n",
    "    # Convert value counts to dictionary\n",
    "    glucose_label_counts_dict = glucose_label_counts.to_dict()\n",
    "\n",
    "    # Log the value counts as a dictionary\n",
    "    logging.info(\"Glucose_Label value counts (as dictionary):\")\n",
    "    logging.info(f\"{glucose_label_counts_dict}\")\n",
    "\n",
    "    # Perform classification\n",
    "    output_data_scaled = output_data[[\"Glucose_Label\"]].values.astype(np.float32)\n",
    "\n",
    "    logging.info(f\"Total size of data: {output_data_scaled.shape[0]}\")\n",
    "\n",
    "    # Split data into intervals\n",
    "    interval_size = 96\n",
    "    intervals = split_into_intervals(intervals, interval_size, interval_size)\n",
    "\n",
    "    last_48 = intervals[:, -interval_split:, :]  # Last 24 entries\n",
    "\n",
    "    intervals = last_48.astype(np.float32)\n",
    "    output_data_scaled = output_data_scaled.astype(np.float32)\n",
    "\n",
    "    feature_size = intervals.shape[2]\n",
    "    num_classes = 2\n",
    "\n",
    "    # Train-Test Split: Keep test set aside (20%)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(intervals, output_data_scaled, test_size=0.2, stratify=output_data_scaled, random_state=42)\n",
    "\n",
    "    # Initialize stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    # Dictionary to store metrics for each model and ID\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    # Initialize stratified 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # List to store the models for evaluation\n",
    "    model_names = ['LSTM', 'Transformer', 'XGBoost', 'DecisionTree', 'RandomForest', 'CNN_LSTM']\n",
    "\n",
    "    # Modified model names with Validation and Test tags\n",
    "    model_names_with_tags = [f\"{name} (Validation)\" for name in model_names] + [f\"{name} (Test)\" for name in model_names]\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    model_results = {model_name: {\n",
    "        'Accuracy': [], \n",
    "        'Precision': [], \n",
    "        'Recall': [], \n",
    "        'F1_Score': [], \n",
    "        'AUC_ROC': [], \n",
    "        'Confusion_Matrix': [], \n",
    "        'Classification_Report': []} for model_name in model_names_with_tags}\n",
    "\n",
    "    ############################ LSTM Model ############################\n",
    "    logging.info(f\"Starting LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(128, input_shape=(interval_split, feature_size), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        lstm_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "        logging.info(f\"LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ Transformer Model ############################\n",
    "    logging.info(f\"Starting Transformer model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define Transformer model\n",
    "        transformer_model = TransformerModel(\n",
    "            input_dim=128,          # Example input dimension (sequence length or feature size)\n",
    "            head_size=64,           # Size of each attention head\n",
    "            num_heads=4,            # Number of attention heads\n",
    "            ff_dim=256,             # Hidden layer size in the feed-forward network\n",
    "            num_transformer_blocks=3, # Number of transformer blocks\n",
    "            mlp_units=[128, 64],    # Units in the multi-layer perceptron (MLP)\n",
    "            num_classes=2,          # Number of output classes (for classification)\n",
    "            dropout=0.1,            # Dropout rate in transformer and feed-forward layers\n",
    "            mlp_dropout=0.1         # Dropout rate in the MLP layers\n",
    "        )\n",
    "\n",
    "        transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        transformer_model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = transformer_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'Transformer (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = transformer_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'Transformer (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del transformer_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Transformer model training and evaluation complete for all folds.\")\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    # Flatten the input data for compatibility with the models\n",
    "    X_full_flattened = intervals.reshape(intervals.shape[0], -1)\n",
    "    y_full = output_data_scaled.flatten()\n",
    "\n",
    "    ############################ XGBoost Model ############################\n",
    "    logging.info(f\"Starting XGBoost model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the XGBoost model\n",
    "        xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = xgb_model.predict(X_val)\n",
    "        y_val_pred_probs = xgb_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'XGBoost (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del xgb_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"XGBoost model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Decision Tree Model ############################\n",
    "    logging.info(f\"Starting Decision Tree model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Decision Tree model\n",
    "        dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = dt_model.predict(X_val)\n",
    "        y_val_pred_probs = dt_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'DecisionTree (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del dt_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Decision Tree model training and testing complete for all folds.\")\n",
    "\n",
    "    ############################ Random Forest Model ############################\n",
    "    logging.info(f\"Starting Random Forest model training with Stratified K-Fold Cross-Validation\")\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_full_flattened, y_full)):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and validation sets for the current fold\n",
    "        X_train, X_val = X_full_flattened[train_index], X_full_flattened[val_index]\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "        y_val_pred_probs = rf_model.predict_proba(X_val)\n",
    "        model_results = capture_metrics(y_val, y_val_pred, y_val_pred_probs, f'RandomForest (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del rf_model, X_train, X_val, y_train, y_val, y_val_pred, y_val_pred_probs\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"Random Forest model training and testing complete for all folds.\")\n",
    "\n",
    "\n",
    "    ############################ CNN-LSTM Model ############################\n",
    "    logging.info(f\"Starting CNN-LSTM model training\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(intervals, output_data_scaled.flatten())):\n",
    "        logging.info(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "        # Split into train and test sets (90% train, 10% test)\n",
    "        X_train_fold, X_test_fold = intervals[train_index], intervals[val_index]\n",
    "        y_train_fold, y_test_fold = output_data_scaled[train_index], output_data_scaled[val_index]\n",
    "\n",
    "        # Further split the training set into train and validation sets (90% train, 10% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.1, stratify=y_train_fold, random_state=42)\n",
    "\n",
    "        # Define CNN-LSTM model\n",
    "        cnn_lstm_model = Sequential([\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(interval_split, feature_size)),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(64),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')  # Multi-class classification\n",
    "        ])\n",
    "\n",
    "        cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Use the custom EpochLogger callback and early stopping\n",
    "        epoch_logger = EpochLogger()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the train-validation split for the current fold\n",
    "        cnn_lstm_model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_val, y_val), verbose=0, callbacks=[epoch_logger, early_stopping])\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred_probs = cnn_lstm_model.predict(X_val)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)\n",
    "        y_val_classes = y_val.flatten()\n",
    "\n",
    "        # Capture and log validation metrics\n",
    "        #model_results = capture_metrics(y_val_classes, y_val_pred_classes, y_val_pred_probs, f'CNN_LSTM (Validation) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # After training, test the model on the test set (held out earlier in the fold)\n",
    "        y_test_pred_probs = cnn_lstm_model.predict(X_test_fold)\n",
    "        y_test_pred_classes = np.argmax(y_test_pred_probs, axis=1)\n",
    "        y_test_classes = y_test_fold.flatten()\n",
    "\n",
    "        # Capture and log test metrics\n",
    "        model_results = capture_metrics(y_test_classes, y_test_pred_classes, y_test_pred_probs, f'CNN_LSTM (Test) Fold {fold + 1}', model_results)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cnn_lstm_model, X_train, X_val, y_train, y_val, y_val_pred_probs, y_val_pred_classes, y_test_pred_probs, y_test_pred_classes\n",
    "        gc.collect()\n",
    "\n",
    "    logging.info(f\"CNN-LSTM model training and evaluation complete for all folds.\")\n",
    "\n",
    "\n",
    "    # Logging the results at the end of each ID processing\n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    logging.info(f\"Processing completed for ID: {id_}\")\n",
    "    \n",
    "    # Manually format and log model results with mean and std deviation\n",
    "    for model_name, metrics in model_results.items():\n",
    "        logging.info(f\"Model: {model_name}\")\n",
    "        \n",
    "        # Log each metric with comma-separated values and compute mean and std\n",
    "        for metric_name in ['Accuracy', 'Precision', 'Recall', 'F1_Score']:\n",
    "            metric_values = metrics[metric_name]\n",
    "            \n",
    "            # Skip calculations for 'AUC_ROC' if it contains invalid data\n",
    "            if metric_name == 'AUC_ROC' and (not metric_values or any(val is None for val in metric_values)):\n",
    "                logging.info(f\"AUC_ROC: Not available due to null values\")\n",
    "                continue\n",
    "            \n",
    "            # Compute mean and std only for valid data\n",
    "            mean_value = np.mean(metric_values) if metric_values else 0\n",
    "            std_value = np.std(metric_values) if metric_values else 0\n",
    "            \n",
    "            # Log the metric values, mean, and std deviation\n",
    "            logging.info(f\"{metric_name}: {', '.join(map(str, metric_values))}\")\n",
    "            logging.info(f\"{metric_name} (Mean): {mean_value:.4f}\")\n",
    "            logging.info(f\"{metric_name} (Std): {std_value:.4f}\")\n",
    "        \n",
    "        # Confusion Matrix and Classification Report can be tricky to format, but here's one way to handle them:\n",
    "        for i, conf_matrix in enumerate(metrics['Confusion_Matrix']):\n",
    "            logging.info(f\"Confusion Matrix {i+1}: {conf_matrix}\")\n",
    "        for i, class_report in enumerate(metrics['Classification_Report']):\n",
    "            logging.info(f\"Classification Report {i+1}: {class_report}\")\n",
    "    \n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    # Store results for the current ID\n",
    "    results[f\"id_{interval_split}\"] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "csv_data = []\n",
    "for id_, model_results in results.items():\n",
    "    for model_name, metrics in model_results.items():\n",
    "        # Convert confusion matrix and classification report to strings (for storage in CSV)\n",
    "        confusion_matrix_str = str(metrics['Confusion_Matrix'])  # Store confusion matrix as string\n",
    "        classification_report_str = metrics['Classification_Report'][0] if isinstance(metrics['Classification_Report'], list) else str(metrics['Classification_Report'])\n",
    "        \n",
    "        csv_data.append({\n",
    "            \"ID\": id_,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean Accuracy\": np.mean(metrics['Accuracy']),\n",
    "            \"Mean Precision\": np.mean(metrics['Precision']),\n",
    "            \"Mean Recall\": np.mean(metrics['Recall']),\n",
    "            \"Mean F1_Score\": np.mean(metrics['F1_Score']),\n",
    "            #\"Mean AUC-ROC\": np.mean(metrics['AUC_ROC']) if metrics['AUC_ROC'][0] != 'N/A' else 'N/A',\n",
    "            \"AUC-ROC List\": metrics['AUC_ROC'] if metrics['AUC_ROC'][0] != 'N/A' else 'N/A',\n",
    "            \"Accuracy List\": metrics['Accuracy'],\n",
    "            \"Precision List\": metrics['Precision'],\n",
    "            \"Recall List\": metrics['Recall'],\n",
    "            \"F1_Score List\": metrics['F1_Score'],\n",
    "            \"Confusion Matrix\": confusion_matrix_str,  # Adding confusion matrix as a string\n",
    "            \"Classification Report\": classification_report_str  # Adding classification report as a string\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(csv_data)\n",
    "df.to_csv(f\"/home/rxb2495/binary_classification_results_{current_time}.csv\", index=False)\n",
    "\n",
    "# Plot results for all models\n",
    "for metric in [\"Mean Accuracy\", \"Mean Precision\", \"Mean Recall\", \"Mean F1_Score\", \"Mean AUC-ROC\"]:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for id_ in ids:\n",
    "        plt.bar(df[df['ID'] == id_]['Model'], df[df['ID'] == id_][metric], label=id_)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} for Different Models and IDs')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
